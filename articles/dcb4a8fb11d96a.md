---
title: "ChatGPTã«æ”¯é…ã•ã‚Œã‚‹å‰ã«ã€æŠ¼ã•ãˆã‚‹ã¹ãAIãƒ»æ©Ÿæ¢°å­¦ç¿’äº‹æƒ…"
emoji: "ğŸ§ "
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["æ©Ÿæ¢°å­¦ç¿’", "AI", "åˆå¿ƒè€…"]
published: false
---

# ç« ç«‹ã¦
1. ã¯ã˜ã‚ã«
1. AIç ”ç©¶ã®å…¨ä½“åƒ
1. AIæŠ€è¡“é–¢é€£å²
1. ä»Šå¾Œã®AIæŠ€è¡“ã«ã¤ã„ã¦
1. ãŠã‚ã‚Šã«

# ã¯ã˜ã‚ã«
AIã«æ”¯é…ã•ã‚Œã†ã‚‹æœªæ¥ãŒè¦‹ãˆå§‹ã‚ã¦ã„ã‚‹ã€‚
ChatGPTã‚’ã¯ã˜ã‚ã¨ã™ã‚‹ç”ŸæˆAIã«ã‚ˆã‚Šã€æŠ€è¡“è€…ã«é™ã‚‰ãšã€AIã«é ¼ã‚‰ã–ã‚‹ã‚’å¾—ãªã„çŠ¶æ³ã«ãªã£ãŸã€‚æŠ€è¡“é€²å±•ã‚¹ãƒ”ãƒ¼ãƒ‰ã¨å½±éŸ¿åŠ›ã‚’è€ƒãˆã‚‹ã¨ã€ã‚ˆã‚Šä¸€å±¤AIãŒå½±éŸ¿ã‚’ä¸ãˆã‚‹ç¯„å›²ã¯åºƒãŒã£ã¦ã„ãã“ã¨ã¯é–“é•ã„ãªã„ã€‚ã—ã‹ã—ç™ºå±•ãŒç›®ã¾ãã‚‹ã—ãã€é«˜åº¦ã™ãã‚‹æŠ€è¡“ã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€ä¸€æœä¸€å¤•ã§ã¯æœ€æ–°ã®AIæŠ€è¡“ã«ã¤ã„ã¦ã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ—ã™ã‚‹ã“ã¨ã¯ã§ããªããªã£ã¦ãŠã‚Šã€ã‚ˆãã‚ã‹ã‚‰ãªã„ã¾ã¾AIã«è§¦ã‚Œã‚‹ã“ã¨ã«ãªã£ã¦ã—ã¾ã£ãŸã‚Šã€AIã¨ã„ã†æŠ€è¡“ãŒå®Ÿã¯ã¨ã£ã¤ãã«ãã„ã‚‚ã®ã«ãªã£ã¦ã—ã¾ã£ãŸã€‚
ãã®çµæœã€ä¸Šè¾ºã ã‘ã®AIè­°è«–ã€éå‰°ãªæœŸå¾…ãƒ»ææ€–ã€ä¸é©åˆ‡ãªåˆ©ç”¨ã‚’æ‹›ã„ã¦ã—ã¾ã†å±é™ºãŒã‚ã‚‹ã€‚ãã—ã¦ãã‚“ãªã“ã¨ã‚’ã—ã¦ã„ã‚‹ã†ã¡ã«AIãŒã‚ˆã‚Šé«˜åº¦ã«ãªã‚Šã€æ°—ã¥ã‹ãªã„ã†ã¡ã«AIãŒäººé–“ã‚’æ”¯é…ã€ã™ãªã‚ã¡å˜ç‹¬ã§äººé–“ç¤¾ä¼šã‚’æœ€é©åŒ–ã—å§‹ã‚ã‚‹ã¨ã„ã†ã“ã¨ã¯ã€ã‚‚ã¯ã‚„èµ·ã“ã‚Šãˆãªã„å¤¢ã®ã§ã¯ãªããªã£ã¦ã„ã‚‹ã€‚ã—ãŸãŒã£ã¦ã€AIã¨ã„ã†ã€ŒæŠ€è¡“ã€ã«å¯¾ã—ã¦å‘ãåˆã†ã“ã¨ã¯ä»Šå¾Œå¤§å¤‰é‡è¦ã«ãªã£ã¦ãã‚‹ã¯ãšã§ã‚ã‚‹ã€‚æœ¬è¨˜äº‹ã§ã¯ã€ã“ã‚Œã‹ã‚‰AIã®å‹‰å¼·ã‚’å§‹ã‚ãŸã„äººã‚„å†åº¦æƒ…å ±ã®æ•´ç†ã‚’ã—ãŸã„äººã«å‘ã‘ã€AIç•Œéšˆã®çŠ¶æ³ã«ã¤ã„ã¦ã¾ã¨ã‚ãŸã€‚

# AIç ”ç©¶ã®å…¨ä½“åƒ
## AIãŒæ‹…ã†ã‚¿ã‚¹ã‚¯
ç¾å®Ÿä¸–ç•Œã§ç”¨ã„ã‚‰ã‚Œã‚‹AIã¯ã€äººé–“ã®è£œåŠ©ï¼ˆäººé–“ã®ä»•äº‹ã‚’æ‰‹ä¼ã†ï¼‰ãƒ»ä»£æ›¿ï¼ˆäººé–“ã®ä»£ã‚ã‚Šã«ä»•äº‹ã‚’ã™ã‚‹ï¼‰ãƒ»æ‹¡å¼µï¼ˆäººé–“ã‚ˆã‚Šã‚‚é«˜åº¦ãªä»•äº‹ã‚’ã™ã‚‹ï¼‰ã¨ã„ã†ç«‹ã¡ä½ç½®ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã€‚æ¬¡ç« ã§è¿°ã¹ã‚‹ãŒã€AIã®ç™ºç«¯ã¯ã€Œäººé–“ã®ã‚ˆã†ãªçŸ¥çš„ãªæ©Ÿæ¢°ã€ã¨ã„ã†ç™ºæƒ³ã§ã‚ã‚‹ã€‚ã—ãŸãŒã£ã¦ã€AIãŒæ‹…ã†ã‚¿ã‚¹ã‚¯ã¯ã€åŸºæœ¬çš„ã«ã¯äººé–“ã®æ´»å‹•ã«ãªãã‚‰ãˆã‚‹ã¨ã‚ˆã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€è¦‹ã‚‹ãƒ»èããƒ»èª­ã‚€ã“ã¨ã§å¾—ãŸæƒ…å ±ã‚’å‡¦ç†ã—ã€æ„æ€æ±ºå®šãƒ»èªè­˜ï¼ˆåˆ†é¡ï¼‰ãƒ»è©±ã™ãƒ»æ›¸ãã‚’è¡Œã†ã“ã¨ã«ãªã‚‹ã€‚

- å…¥åŠ›
    - è¦‹ã‚‹
    - èã
    - èª­ã‚€
- å‡ºåŠ›
    - æ„æ€æ±ºå®š
    - èªè­˜ï¼ˆåˆ†é¡ï¼‰
    - è¨€ã†
    - æ›¸ã

> **note**
å—…è¦šãƒ»è§¦è¦šãƒ»å‘³è¦šã«é–¢ã™ã‚‹ã‚»ãƒ³ã‚µãƒ¼ãŒä¸€èˆ¬çš„ã§ãªã„ãŸã‚ã€ãã‚Œã‚‰ã‚’å…¥åŠ›ã¨ã™ã‚‹AIã¯ã¾ã å°‘ãªã„ãŸã‚ã€è¨˜è¼‰ã—ã¦ã„ãªã„ã€‚ä»Šå¾Œã€ç¬¬å…­æ„Ÿã«ã‚‚æœŸå¾…ã€‚

## ç”¨èªãƒ»åˆ†é¡
AI
- Symbolic AIï¼ˆSymbolic reasoningï¼‰
- Subsymbolic AI
- Machine learning

Symbolicã¨Connectionistã¯Learning systemãŒé•ã†
https://www.linkedin.com/pulse/what-artificial-intelligence-without-machine-learning-claudia-pohlink/

## ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¨AIãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®é•ã„
å›ºå®šå‹•ä½œï¼šãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆäººé–“ã®åè¦‹ã®å½±éŸ¿ã‚’å—ã‘ã‚‹ï¼‰
è‡ªå·±èª¿æ•´ã™ã‚‹ï¼šAIï¼ˆäººé–“ã®æƒ³å®šã‚’è¶…ãˆã‚‹ï¼‰ã€ç­”ãˆãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚ã‹ã‚‰ãªã„å•é¡Œã«å–ã‚Šçµ„ã‚€ã€ç­”ãˆãŒæƒ³å®šã•ã‚Œã™ãã¦ã„ãªã„
 
## ç ”ç©¶ã®è¦–ç‚¹
ãŠã‚ˆãã€ä¸‹è¨˜ã®3ã¤ã®è¦–ç‚¹ã§ã®ç ”ç©¶æ´»å‹•ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚ãŸã ã—ã€ãã‚Œãã‚Œå½±éŸ¿ã‚’ä¸ãˆåˆã£ã¦ã„ã‚‹ãŸã‚ã€å–ã‚Šçµ„ã¿ã‚’ãã‚Œãã‚Œã«åˆ†é¡ã™ã‚‹ã“ã¨ã¯é›£ã—ã„ã€‚
- Architechture
AIãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ï¼ˆä¾‹ï¼šã©ã‚“ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’çµ„ã‚€ã‹ï¼‰
- Optimization
ã©ã®ã‚ˆã†ã«æ¨è«–ãƒ¢ãƒ‡ãƒ«ã‚’æœ€é©åŒ–ã™ã‚‹ã‹ï¼ˆä¾‹ï¼šãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã©ã®ã‚ˆã†ã«æ±ºã‚ã‚‹ã‹ï¼‰
èª²é¡Œï¼šå±€æ‰€è§£ã€éå‡¸å•é¡Œ
- Generalization
ã©ã‚“ãªå•é¡Œã§ã‚‚å¯¾å¿œã§ãã‚‹ã‹ï¼ˆä¾‹ï¼šå­¦ç¿’ã—ãŸãƒ‡ãƒ¼ã‚¿ä»¥å¤–ã®å ´åˆã«ã‚‚å¯¾å¿œã§ãã‚‹ã‹ã€ãƒã‚¤ã‚ºè€æ€§ï¼‰

# AIæŠ€è¡“é–¢é€£å²ã€€ã€€
AIæŠ€è¡“ã«å¯¾ã™ã‚‹æœŸå¾…ã¨ã¯

##  ~ 1957å¹´ã”ã‚ï¼šã€ŒAIã€èª•ç”Ÿ
17ä¸–ç´€ã«æ´»èºã—ãŸãƒ‰ã‚¤ãƒ„ã®å­¦è€…[Gottfried Wilhelm Leibniz](https://en.wikipedia.org/wiki/Gottfried_Wilhelm_Leibniz)ã¯ã€å®‰å…¨ãƒ»æ™‚é–“æµªè²»ã®è¦³ç‚¹ã‹ã‚‰è¨ˆç®—ã¯äººé–“ã§ã¯ãªãæ©Ÿæ¢°ãŒã™ã‚‹ã¹ãã§ã‚ã‚‹ã¨ã„ã†è€ƒãˆæ–¹ã‚’æŒã£ã¦ãŠã‚Šã€[Pascalã®è¨ˆç®—æ©Ÿ](https://en.wikipedia.org/wiki/Pascal%27s_calculator)ã‚’ã‚‚ã¨ã«ã—ã¦ã€é•·ã•ã®ç•°ãªã‚‹æ­¯ã‚’ã‚‚ã¤ã‚·ãƒªãƒ³ãƒ€ãƒ¼ã¨ç§»å‹•å¼ã®æ­¯è»Šã‚’çµ„ã¿åˆã‚ã›ã¦è¨ˆç®—ï¼ˆåŸºæœ¬çš„ã«ã¯è‡ªç„¶æ•°ã®å››å‰‡æ¼”ç®—ï¼‰ã‚’å¯èƒ½ã«ã—ãŸStepped reckonerã¾ãŸã¯Leibniz Wheelï¼ˆãƒ©ã‚¤ãƒ—ãƒ‹ãƒƒãƒ„ã®è»Šè¼ªï¼‰ã¨å‘¼ã°ã‚Œã‚‹æ‰‹å‹•æ©Ÿæ¢°å¼ã®è¨ˆç®—æ©Ÿã‚’ã€1694å¹´ã«å®Œæˆã•ã›ãŸ[^10-4] [^10-5]ã€‚ã“ã‚Œã‚’ãã£ã‹ã‘ã«Leibnizã¯ã€æ•°å­¦çš„è¨˜è¿°ï¼ˆmathmatical statementã€è©³ç´°ã¯ä»¥ä¸‹ã®**note 1**ã‚’å‚ç…§ï¼‰ã®çœŸç†å€¤ã‚’æ±ºå®šã§ãã‚‹æ©Ÿæ¢°ã‚’ä½œã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§ã¯ãªã„ã‹ã¨è€ƒãˆã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚ãã‚ŒãŒå®Ÿç¾ã§ãã‚‹ã¨ã€æ©Ÿæ¢°ãŒè«–ç†ã‚’æ‰±ã†ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ãŸã‚ã€ã©ã†ã„ã†å ´åˆã«ã¯ä½•ã‚’ã™ã‚‹ã¨ã„ã£ãŸ**å ´åˆåˆ†ã‘å‡¦ç†**ã‚„ã€æ˜ç¢ºãªç†ç”±ãŒã‚ã‚‹**æ¨è«–**ã¨ã„ã£ãŸ[^10-8]ã€ã‚ˆã‚ŠçŸ¥çš„ãªå‡¦ç†ãŒå¯èƒ½ã«ãªã‚‹ã€‚æ©Ÿæ¢°ãŒè«–ç†ã‚’æ‰±ã†ãŸã‚ã«ã¯ã€äººé–“ãŒè‡ªç„¶ã«è¡Œã£ã¦ã„ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚ˆã†ãªã€æ›–æ˜§ã•ãŒæ®‹ã‚‹è¡¨ç¾ã‚„ãã®æ™‚ã«ã‚ˆã£ã¦ç”¨æ³•ãƒ»æ„å‘³ãŒå¤‰ã‚ã‚‹ã‚ˆã†ãª**è‡ªç„¶è¨€èª**ï¼ˆnatual langageï¼‰ã§ã¯ãªãã€æ–‡æ³•ãƒ»æ„å‘³ãŒå½¢å¼çš„ã«ä¸ãˆã‚‰ã‚Œã¦æ˜ç¢ºã«è«–ç†ãŒå±•é–‹ã§ãã‚‹**å½¢å¼è¨€èª**ï¼ˆformal languageï¼‰ãŒå¿…è¦ã§ã‚ã‚‹ã¨è€ƒãˆã€Leibnizã®ç ”ç©¶ã¯å½¢å¼è¨€èªã‚’ç”¨ã„ãŸ**å½¢å¼ç†è«–**ï¼ˆformal theoryï¼‰ã«ã‚‚é‡ããŒç½®ã‹ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã£ãŸã€‚ã•ã‚‰ã«ã€Leibnizã¯æ´»å‹•ã®ä¸­ã§ã€ç¾ä»£ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®åŸºç¤ã¨ãªã£ã¦ã„ã‚‹2é€²æ•°æ¼”ç®—ï¼ˆbinary arithmeticsï¼‰ã‚„[^10-9]ã€2é€²æ•°ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ï¼ˆbinary computerï¼‰ã«ã¤ã„ã¦ã‚‚åŠŸç¸¾ã‚’æ®‹ã—ã¦ã„ã‚‹[^10-10]ã€‚
*ä¸Šè¨˜è­°è«–ã¨Symbolã¨ã®é–¢ä¿‚*

> **note 1**
æ•°å­¦çš„è¨˜è¿°ï¼ˆmathmatical statementï¼‰ã¯ã€æ­£ã—ã„ï¼ˆçœŸï¼‰ã‹é–“é•ã£ã¦ã„ã‚‹ï¼ˆå½ï¼‰ã‹ãŒåˆ¤æ–­ã§ãã‚‹ã€Œæ–‡ã€ã§ã‚ã‚Šã€è¨€è‘‰ã‚„è¨˜å·ï¼ˆsymbolï¼‰ãŒå«ã¾ã‚Œã‚‹ã€‚ä¾‹ãˆã°ã€è¨€è‘‰ã‚’ä½¿ã£ãŸã€Œ1ã¯2ã‚ˆã‚Šã‚‚å¤§ãã„ã€ã‚„ã€è¨˜å·ã‚’ä½¿ã£ãŸã€Œ1>2ã€ã¨ã„ã†æ–‡ã¯ã€ã€Œå½ã€ã§ã‚ã‚‹mathmatical statementã§ã‚ã‚‹ã€‚

Leibnizã®è«–æ–‡ãŒãƒ‰ã‚¤ãƒ„ã®Hannoverã§é–²è¦§å¯èƒ½ã«ãªã£ãŸ1830å¹´ä»£ä»¥é™ã€ãã®æ³¨ç›®åº¦ã¯æ€¥é€Ÿã«é«˜ã¾ã‚Šã€Johann Eduard Erdmannã‚„Kurt GÃ¶delãªã©å¾Œã®ç ”ç©¶ã«å¤šå¤§ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹[^10-11] [^10-12]ã€‚ã“ã®é ƒã€æ•°å­¦ç•Œã§ã¯æ•°å­¦ç†è«–ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®æ¼”ç¹¹çš„ãªæ–¹æ³•ï¼ˆã™ã§ã«çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹æ³•å‰‡ï¼ˆä¸€èˆ¬è«–ãƒ»ãƒ«ãƒ¼ãƒ«ï¼‰ã‚„å‰æã‹ã‚‰ã€éšæ®µã‚’ç™»ã£ã¦ã„ãã‚ˆã†ã«è«–ç†ã‚’ç©ã¿é‡ã­ã¦çµè«–ã‚’å‡ºã™è€ƒãˆæ–¹[^10-13]ï¼‰ã«æ³¨ç›®ãŒé›†ã¾ã£ã¦ãŠã‚Šã€æ•°å­¦ã«ãŠã‘ã‚‹å½¢å¼ç†è«–ï¼ˆå…¬ç†ç†è«–ã¨ã‚‚ã„ã†ï¼‰ã«é–¢ã™ã‚‹æ–°ã—ã„å•é¡ŒãŒæèµ·ã•ã‚Œã¦ã„ãŸ[^10-14]ã€‚1928å¹´ã€ãƒ‰ã‚¤ãƒ„ã®æ•°å­¦è€…ã§ã‚ã‚‹David Hilbertã¨Wilhelm Ackermannã¯ã€**Entscheidungsproblem**ï¼ˆãƒ‰ã‚¤ãƒ„èªã€‚æ—¥è¨³ã§æ±ºå®šå•é¡Œã€è‹±è¨³ã§decision problemï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã€ã€Œï¼ˆä¸€éšè«–ç†ã®ï¼‰ã™ã¹ã¦ã®æ•°å­¦çš„è¨˜è¿°ã¯ã€å°å‡ºå¯èƒ½ã‹ã€ï¼ˆã™ã¹ã¦ã®å…¬ç†ã‚’è€ƒæ…®ã™ã‚Œã°ã€å‘½é¡ŒãŒè¨¼æ˜å¯èƒ½ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã§ãã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ã©ã†ã‹ï¼‰ã¨ã„ã†å•é¡Œã‚’æèµ·ã—ãŸ[^10-15]ã€‚ã“ã®å•é¡Œã¯ã€ã€Œäººé–“ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ã™ã¹ã¦å˜ç´”ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§è¡¨ç¾ã™ã‚‹ã“ã¨ã¯å¯èƒ½ã‹ã€ã¨è¨€ã„æ›ãˆã‚‹ã“ã¨ãŒã§ã[^10-18]ã€ã‚‚ã—ãã®ã‚ˆã†ãªã“ã¨ãŒå¯èƒ½ã§ã‚ã‚Œã°ã€å˜ç´”ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã ã‘ã§ã‚‚å®Ÿè¡Œå¯èƒ½ãªæ©Ÿæ¢°ãŒã‚ã‚Œã°ã€äººé–“ã®æ€è€ƒæ´»å‹•ã‚’å…¨ã¦ãã‚Œã§å†ç¾ã§ãã‚‹ã¨ã„ã†ã“ã¨ã«ãªã‚‹ã€‚

Note that in its original form (Hilbert & Ackermann 1928), the problem was stated in terms of validity rather than derivability. Given GÃ¶delâ€™s completeness theorem (GÃ¶del 1929) proving that there is an effective procedure (or not) for derivability is also a solution to the problem in its validity form. In order to tackle this problem, one needs a formalized notion of â€œeffective procedureâ€ and Turingâ€™s machines were intended to do exactly that

> **note 2**
æ•°å­¦è€…ã‚„æ•°å­¦å›£ä½“ã¯è‡ªèº«ãŒç™ºæ¡ˆãƒ»ç›´é¢ã—ãŸæœªè§£æ±ºå•é¡Œã‚’å…¬é–‹ã—ã€ç ”ç©¶ã‚’ç”Ÿã¿å‡ºã—ã¦ããŸã€‚1900å¹´ã«HilbertãŒã€ãƒ‘ãƒªã§é–‹å‚¬ã•ã‚ŒãŸå›½éš›æ•°å­¦è€…ä¼šè­°ï¼ˆInternational Congress of Mathematicians: ICMï¼‰ãŠã‚ˆã³å½¼ã®è‘—ä½œã§ã€æ¬¡ã®ä¸–ç´€ã«ç ”ç©¶ã•ã‚Œã‚‹ã¹ã23ã®ä¸»è¦ãªæ•°å­¦çš„å•é¡ŒãŒç™ºè¡¨ã•ã‚ŒãŸ[^10-1] [^10-2] [^10-3]ã€‚Entscheidungsproblemã¯[Hilbertã®23ã®å•é¡Œ](https://ja.wikipedia.org/wiki/%E3%83%92%E3%83%AB%E3%83%99%E3%83%AB%E3%83%88%E3%81%AE23%E3%81%AE%E5%95%8F%E9%A1%8C)ã®ã†ã¡ã€[Diophantineæ–¹ç¨‹å¼](https://en.wikipedia.org/wiki/Diophantine_equation)ã«è§£ãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’æ±ºå®šã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ±‚ã‚ã‚‹ç¬¬10å•é¡Œã«é–¢é€£ã—ã¦ã„ã‚‹ã€‚ï¼ˆ**ç¬¬2å•é¡Œã‚‚ï¼Ÿï¼Ÿ** // Church-turing thesisï¼‰

1935å¹´ã€Hilbertã®Entscheidungsproblemã«èˆˆå‘³ã‚’æŒã£ãŸAlan Turingã¯ã€ä»»æ„ã®æ•°å­¦çš„è¨˜è¿°ã®å°å‡ºã«å¿…è¦ãªã€Œå½¢å¼åŒ–ã•ã‚ŒãŸæ‰‹é †ã€ãŒå¿…è¦ã§ã‚ã‚‹ã€ã¨ã—ã¦ç ”ç©¶ã‚’é–‹å§‹ã—ãŸã€‚ã™ãªã‚ã¡ã€ã©ã‚“ãªæ•°å­¦çš„è¨˜è¿°ã‚‚å°å‡ºã§ãã‚‹æ‰‹é †ãŒå­˜åœ¨ã™ã‚‹ã¨ã„ã†ã“ã¨ã¯ã€ã©ã‚“ãªæ•°å­¦çš„è¨˜è¿°ã‚‚è¨¼æ˜å¯èƒ½ã§ã‚ã‚‹ã¨è¨€ãˆã‚‹ã€ã¨ã„ã†è€ƒãˆæ–¹ã§ã‚ã‚‹ã€‚Turingã¯ç¿Œ1936å¹´ã«ç™ºè¡¨ã—ãŸè«–æ–‡[^10-22]ã§ã€ãã†ã„ã†æ‰‹é †ãŒå¯èƒ½ã§ã‚ã‚‹ä»®æƒ³çš„ãªæ©Ÿæ¢°ï¼ˆUTM: **Universal Turing machine**[^10-26]ï¼‰ã‚’è€ƒæ¡ˆã—ã€EntscheidungsproblemãŒæˆã‚Šç«‹ãŸãŸãªã„ã“ã¨ã‚’è¨¼æ˜ã—ãŸ[^10-17] [^10-18] [^10-19] [^10-20]ã€‚ã—ãŸãŒã£ã¦ä¾‹ãˆã°ã€æ•°å­¦ã®å®šç†ã‚’è¨¼æ˜ã™ã‚‹ãŸã‚ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„ãªæ‰‹æ³•ã¯å­˜åœ¨ã›ãšã€ç·å½“ãŸã‚Šï¼ˆBrute forceï¼‰çš„ã«è¨¼æ˜ã‚’è©¦ã•ãªã‘ã‚Œã°ãªã‚‰ãªã„ã¨ã„ã†ã“ã¨ãŒç¤ºã•ã‚ŒãŸã“ã¨ã«ãªã‚‹[^10-54]ã€‚
Turingã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ç‹¬å‰µçš„ã ã£ãŸã®ã¯ã€UTMã‚’è€ƒæ¡ˆã™ã‚‹ã«ã‚ãŸã‚Šã€ãã‚Œã¾ã§ç™ºæ˜ã•ã‚Œã¦ã„ãŸã€Œæ©Ÿæ¢°ã€ã«æ³¨ç›®ã™ã‚‹ã®ã§ã¯ãªãã€å­ä¾›ãŒå‹‰å¼·ã§ä½¿ã†æ–¹çœ¼ç´™ã‚„ä½•ã‹æ‰‹é †ã‚’è¸ã‚€ã¨ãã®äººé–“ã®æ€è€ƒãªã©ã€ã€Œäººé–“ã€ã«æ³¨ç›®ã—ãŸä¸Šã§ã€å®Ÿè¡Œã™ã‚‹æ‰‹é †ã‚’å¾¹åº•çš„ã«æ›–æ˜§ã•ãŒãªã„è«–ç†çš„ãªå‡¦ç†ã«è½ã¨ã—è¾¼ã‚“ã ã“ã¨ã§ã‚ã‚‹[^10-21]ã€‚
UTMã®è«–ç†æ€§ã¯ã€1943å¹´ã«ç™ºè¡¨ã•ã‚ŒãŸã€ç¥çµŒç”Ÿç†å­¦è€…Warren McCullochã¨æ•°å­¦è€…Walter Pittsã«ã‚ˆã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ•°å­¦ãƒ¢ãƒ‡ãƒ«ï¼ˆMPãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€MCPãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¨å‘¼ã°ã‚Œã‚‹ï¼‰ãŠã‚ˆã³ãã‚Œã«ã‚ˆã‚Šæ§‹æˆã•ã‚Œã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‡ãƒ«ã®è€ƒæ¡ˆã®ãŸã‚ã®ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚‚ãŸã‚‰ã—[^10-23] [^10-47]ã€UTMã®æ§‹æˆï¼ˆ**note 4**å‚ç…§ï¼‰ã¯ã€Machineã¸ã®å‘½ä»¤ã‚’å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜è¨˜æ†¶é ˜åŸŸã«é…ç½®ã™ã‚‹stored-programæ–¹å¼ã¨å‘¼ã°ã‚Œã€1945å¹´ã«ã‚¢ãƒ¡ãƒªã‚«ã®å­¦è€…John von Neumannã«ã‚ˆã‚Šç™ºè¡¨ã•ã‚ŒãŸã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®æ§‹æˆï¼ˆãƒã‚¤ãƒãƒ³å‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€von Neumann modelã€Princeton architectureãªã©ã¨å‘¼ã°ã‚Œã‚‹ï¼‰ã«ã‚‚å¼·ã„å½±éŸ¿ã‚’ä¸ãˆã‚‹ãªã©[^10-24] [^10-25] [^10-26]ã€å¤šå¤§ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã¨ãªã£ãŸã€‚
ãƒã‚¤ãƒãƒ³å‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒç™ºè¡¨ã•ã‚ŒãŸ1945å¹´æœ«ã«ã¯ã€ä¸–ç•Œåˆã®ã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒ å¯èƒ½ãªï¼ˆå‘½ä»¤ã®ä¸ãˆæ–¹ã«ã‚ˆã£ã¦æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™ã“ã¨ãŒã§ãã‚‹ï¼‰ã€è¨ˆç®—æ©Ÿã§ã‚ã‚‹ENIACï¼ˆElectronic Numerical Integrator and Computerï¼‰[^10-27] [^10-28]ã€1948å¹´ã«ã¯ä¸–ç•Œã§åˆã‚ã¦ãƒã‚¤ãƒãƒ³å‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§å‹•ä½œã™ã‚‹Manchester Babyï¼ˆSSEM: Small-Scale Experimental Machineã¨ã‚‚å‘¼ã°ã‚Œã‚‹ï¼‰ãªã©[^10-29] [^10-30]ã€ç¶šã€…ã¨é›»å­è¨ˆç®—æ©Ÿï¼ˆä»¥é™ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ï¼‰ãŒä¸€èˆ¬åŒ–ã—ï¼ˆãªã‚“ã§ã‚‚ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šï¼‰ã€åŒæ™‚ã«é«˜æ€§èƒ½åŒ–ã—ã¦ã„ã£ãŸã€‚
ã•ã‚‰ã«1951å¹´ã«ã¯ã€Marvin Minskyã¨Dean EdmondsãŒã€SNARCï¼ˆStochastic Neural Analog Reinforcement Calculatorï¼‰ã¨ã„ã†ä¸–ç•Œã§åˆã‚ã¦äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆANN: Artificial Neural Networkï¼‰ã‚’å®Ÿè£…ã—ãŸã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã—ã¦ã„ã‚‹ã€‚SNARCã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€MPãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®è€ƒãˆæ–¹ã‚’æ‹¡å¼µã—ãŸHebbç†è«–ã«åŸºã¥ã„ã¦ãŠã‚Šã€**å­¦ç¿’**ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚
Hebbç†è«–ã¯ã€1949å¹´ã«ã‚«ãƒŠãƒ€ã®å¿ƒç†å­¦è€…Donald Olding Hebã®[è‘—æ›¸](https://pure.mpg.de/rest/items/item_2346268_3/component/file_2346267/content)ã§æå”±ã•ã‚ŒãŸ[^10-48]ã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ•°å­¦ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ«ãƒ¼ãƒ«ã¨ãã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å«ã‚€ç†è«–ã§ã‚ã‚‹ã€‚Hebbã¯ã€ã¤ãªãŒã£ã¦ã„ã‚‹2ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒåŒæ™‚ã«ç™ºç«ã™ã‚Œã°ã™ã‚‹ã»ã©ã€ãã‚Œã‚‰ã®æ¥ç¶šå¼·åº¦ï¼ˆä»¥é™ã€é‡ã¿ï¼‰ã¯å¼·ããªã‚‹ã¨ã„ã†è¦å‰‡ã‚’ä¸»å¼µã—ãŸï¼ˆã“ã‚Œã¯ã€å¾Œã«é•·æœŸè¨˜æ†¶ã®ç†è«–ã«ã‚‚å½±éŸ¿ã—ãŸï¼‰[^10-52]ã€‚ã“ã®è¦å‰‡ã«åŸºã¥ã„ã¦é‡ã¿ã‚’èª¿æ•´ã™ã‚Œã°ã€ãƒ­ã‚¸ãƒƒã‚¯ãŒå¤‰ãˆã‚‰ã‚Œã‚‹ã€ã™ãªã‚ã¡æ‰€æœ›ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¾—ã‚‹ãŸã‚ã«é‡ã¿ã‚’èª¿æ•´ã™ã‚Œã°ã€æ©Ÿæ¢°ãŒæ”¹å–„ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚‹ãŸã‚ã€Œå­¦ç¿’ã€ã¨å‘¼ã¶ã“ã¨ãŒã§ãã‚‹ï¼ˆSNARCã§ã¯Hebbå‰‡ã«åŸºã¥ã„ã¦é‡ã¿ã®æ›´æ–°ã‚’äººã®æ‰‹ã§è¡Œã£ã¦ã„ãŸï¼‰[^10-50]ã€‚
ãŸã ã—ã€ç´”ç²‹ãªç·å½“ãŸã‚Šå‡¦ç†ã‚’ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦è¡Œã†è¨ˆç®—ã¯ã“ã®é ƒã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®æ€§èƒ½ã§ã¯ä¸å¯èƒ½ã§ã‚ã‚Š[^10-55]ã€ç‰¹ã«æ¢ç´¢ã‚„èªè­˜ã¨ã„ã£ãŸè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã¯ã€çŸ¥æ€§çš„ã«è§£ã‚’æ±‚ã‚ã‚‹æ–¹æ³•ãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ãŸã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ã•ã‚‰ã«1949å¹´ã€ã‚¢ãƒ¡ãƒªã‚«ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ç§‘å­¦è€…Edmund BerkeleyãŒè‘—æ›¸*Giant Brains, or Machines That Think*ã§ã€ŒA machine, therefore, can think.ã€ã¨è¨€åŠã—[^10-32] [^10-33] [^10-34]ã€1950å¹´ã«TuringãŒç™ºè¡¨ã—ãŸè«–æ–‡ã‚’ã€ŒI PROPOSE to consider the question, â€˜Can machines think?â€™ã€ã§å§‹ã‚ã‚‹ãªã©[^10-35]ã€æ€è€ƒã™ã‚‹æ©Ÿæ¢°ã¸ã®é–¢å¿ƒã¯ã•ã‚‰ã«ç››ã‚Šä¸ŠãŒã‚Šã‚’è¦‹ã›ã¦ã„ãŸã€‚Turingã¯ãã®è«–æ–‡ã§Turing Testã¨ã„ã†éå¸¸ã«é‡è¦ãªã€‚ã€‚ã€‚ï¼ˆTuring Testã«ã¤ã„ã¦è©³ç´°ã¯å‰²æ„›ï¼‰ã€‚

> **note 3**
Turing machineã¨Universal Turing Machineã®é•ã„

> **note 4**
Turing machineã¯è‡ªèº«ã®è«–æ–‡ã®ä¸­ã§computing machineã¨å‘¼ã°ã‚Œ[^10-22]ã€ç„¡é™é•·ã®ãƒ†ãƒ¼ãƒ—ã¨ã€‚è©³ç´°ã¯å‰²æ„›ã€‚

1954å¹´ã«RANDï¼ˆResearch and Developmentï¼‰Corporationã§ã€JOHNNIACï¼ˆJohn von Neumann Numerical Integrator and Automatic Computerã®ç•¥ã§von Neumannã‚‚é–‹ç™ºã«æºã‚ã£ãŸï¼‰ã¨ã„ã†è¨ˆç®—æ©ŸãŒæ§‹ç¯‰ã•ã‚Œ[^10-36]ã€ç¿Œå¹´ã«ã‹ã‘ã¦ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ç§‘å­¦è€…ãƒ»èªçŸ¥å¿ƒç†å­¦è€…ã®Allen Newellã¨æ”¿æ²»ãƒ»çµŒæ¸ˆãƒ»ç¤¾ä¼šå­¦è€…ã®Herbert Simonã‚’ä¸­å¿ƒã«Logic Theoristã¨å‘¼ã°ã‚Œã‚‹ã€IPLï¼ˆInformation Processing Languageã¨ã„ã†ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªï¼‰ã‚’ç”¨ã„ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒä½œæˆã•ã‚ŒãŸ[^10-37] [^10-38] [^10-39]ã€‚Logic Theoristã¯ã€äººé–“ã®æ•°å­¦è€…ã®é ­è„³ã®èƒ½åŠ›ã‚’æ¨¡å€£ã™ã‚‹ã‚ˆã†ã«ã€Symbolã‚’çµ„ã¿åˆã‚ã›ã¦è¡¨ç¾ã«çµ„ã¿è¾¼ã‚€ã€Œsymbolic reasoningã€ã¨å‘¼ã°ã‚Œã‚‹æ¨è«–ã«åŸºã¥ã„ã¦ãŠã‚Š[^10-41]ã€å…ƒã«ãªã‚‹æ•°å­¦å®šç†ã®ã‹ã‚‰æ–°ã—ã„å®šç†ã‚’è¨¼æ˜ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã‚ã‚‹ï¼ˆã—ã‹ã‚‚ã„ãã¤ã‹ã®æ•°å­¦å®šç†ã¯ã€äººé–“ã®æ•°å­¦è€…ã‚ˆã‚Šã‚‚è©³ç´°ãªè¨¼æ˜ã‚’ç¤ºã™ã“ã¨ãŒã§ããŸï¼‰[^10-37]ã€‚ã“ã®ã‚ˆã†ã«ã€åŸºã«ã™ã‚‹è¦ç´ ï¼ˆrootï¼‰ã‹ã‚‰è«–ç†è¦å‰‡ã«åŸºã¥ã„ã¦åˆ†å²ã—ãªãŒã‚‰ç›®çš„ã®è¦ç´ ã‚’æ¢ç´¢ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ä»Šæ—¥ã§ã‚‚æ¢ç´¢æœ¨ï¼ˆsearch treeï¼‰ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ãŠã‚Šã€Logic Theoristã¯è§£ã‘ã‚‹ä¿è¨¼ãŒãªã„å•é¡Œã«å–ã‚Šçµ„ã‚€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œæˆã—ãŸç‚¹ãŒä¸€ã¤ã®å¤§ããªç™ºæ˜ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ã¾ãŸã€Logic Theoristã¯å®Ÿéš›ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«äººé–“ã®æ¨è«–èƒ½åŠ›ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ãŸä¸–ç•Œåˆã®äººå·¥çŸ¥èƒ½ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¨ç§°ã•ã‚Œ[^10-51]ã€Symbolã‚’ç”¨ã„ã¦äººé–“ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ åŒ–ã™ã‚‹ã„ã†æ€æƒ³ã«åŸºã¥ã„ãŸã“ã®ã‚ˆã†ãªæ‰‹æ³•ã¯å¾Œã«ã€**Symbolic AI**ã«åˆ†é¡ã•ã‚Œã‚‹[^10-42]ã€‚Symbolic AIã«å¯¾ã—ã¦ã€äººé–“ã®è„³ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚Œã°äººé–“ã¨åŒã˜ã‚ˆã†ã«çŸ¥èƒ½ã‚’ã‚‚ãŸã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã¨ã„ã†æ€æƒ³ã«åŸºã¥ã„ã¦ã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ•°å­¦ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ANNã‚’æ§‹æˆã™ã‚‹æ‰‹æ³•ã¯**Connectionist AI**ã¨å‘¼ã°ã‚Œã‚‹[^10-49]ã€‚
Heuristics? Reasoning search?
Logic AI
https://plato.stanford.edu/entries/logic-ai/

ä¸Šè¨˜ã®ã‚ˆã†ã«ã€ã“ã®é ƒã€ã€Œè€ƒãˆã‚‹æ©Ÿæ¢°ï¼ˆthinking machineï¼‰ã€ã«é–¢ã™ã‚‹å–ã‚Šçµ„ã¿ãŒéå¸¸ã«æ´»ç™ºã ã£ãŸã¨è¨€ãˆã‚‹ãŒã€Dartmouthå¤§å­¦ã®æ•°å­¦åŠ©æ•™æˆã ã£ãŸJohn McCarthyãŒã‚ˆã‚Šæ˜ç¢ºã«ãã®ç ”ç©¶é ˜åŸŸã‚’ç™ºå±•ã•ã›ã‚‹ãŸã‚ã«[^10-45]ã€DSRPAIï¼ˆDartmouth Summer Research Project on Artificial Intelligenceã€ãƒ€ãƒ¼ãƒˆãƒã‚¹ä¼šè­°ï¼‰ã§Rockefellerè²¡å›£ã«ã‚»ãƒŸãƒŠãƒ¼ã®ãŸã‚ã®è³‡é‡‘æä¾›ã‚’è¦è«‹ã—ã€ãã®ç ”ç©¶é ˜åŸŸã‚’**äººå·¥çŸ¥èƒ½**ï¼ˆ**Artificial Intelligence**ï¼‰ã¨åä»˜ã‘ãŸ[^10-44]ã€‚ã“ã‚ŒãŒã€AIã¨ã„ã†ç”¨èªãŒä½¿ã‚ã‚ŒãŸæœ€åˆã®æ–‡æ›¸ã§ã‚ã‚Š[^10-46]ã€ã“ã‚ŒãŒAIã¨ã„ã†ç ”ç©¶åˆ†é‡ã®èª•ç”Ÿã¨ã•ã‚Œã‚‹ï¼ˆ1956å¹´ã«DSRPAIãŒé–‹å‚¬ã•ã‚Œã€Logic theoristã¯ãã“ã§ç™ºè¡¨ã•ã‚ŒãŸ[^10-43]ï¼‰ã€‚

> **note 5**
Research and Development (RAND) Corporationã¨ã¯ï¼ˆå‰²æ„›ï¼‰

> **note 7**
> John McCarthyã®è¦è«‹åŸæ–‡
We propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.

[^10-1]: [Hilbertâ€™s Problems: 23 and Math](https://www.simonsfoundation.org/2020/05/06/hilberts-problems-23-and-math/)
[^10-2]: [The Mathematical Problems of David Hilbert](http://aleph0.clarku.edu/~djoyce/hilbert/)
[^10-3]: [Gottfried Wilhelm Leibniz: An Optimistic Polymath](https://www.historyofdatascience.com/gottfried-wilhelm-leibniz-an-optimistic-polymath/)
[^10-4]: [Stepped reckoner in *Wikipedia*](https://en.wikipedia.org/wiki/Stepped_reckoner)
[^10-5]: [Calculus on Demand](https://math.dartmouth.edu/~m3cod/LeibnizWheelBig.htm)
[^10-6]: [Turing, Leibniz and Hilbertâ€™s Entscheidungsproblem](https://3010tangents.wordpress.com/2014/11/26/turing-leibniz-and-hilberts-entscheidungsproblem/)
[^10-7]: [Mathematical Statements](https://www.math.toronto.edu/preparing-for-calculus/3_logic/we_1_statements.html)
[^10-8]: [Why Logic is Important for Computer Science and Mathematics](https://www.cs.utexas.edu/~rlc/whylog.htm)
[^10-9]: [EXPLANATION OF BINARY ARITHMETIC](https://www.leibniz-translations.com/binary.htm)
[^10-10]: G. Leibniz. De Progressione dyadica Pars I. 15 March 1679. [Principles of binary computers governed by punch cards.]
[^10-11]: [Leibnizâ€™s Influence on 19th Century Logic](https://plato.stanford.edu/entries/leibniz-logic-influence/#SecWavRec)
[^10-12]: [2021: 375th birthday of Leibniz, founder of computer science](https://people.idsia.ch/~juergen/leibniz-father-computer-science-375.html)
[^10-13]: [æ¼”ç¹¹æ³•ã¨å¸°ç´æ³•ã®é•ã„ã¨ã¯ï¼Ÿè€ƒãˆæ–¹ã‚„é›ãˆæ–¹ã‚’ã”ç´¹ä»‹](https://solution.lmi.ne.jp/column/c198)
[^10-14]: [Axiomatic method](https://encyclopediaofmath.org/index.php?title=Axiomatic_method)
[^10-15]: [The Entscheidungsproblem and Alan Turing](https://www.gcsu.edu/sites/files/page-assets/node-808/attachments/brodkorb.pdf)
[^10-16]: [Entscheidungsproblem in *Wikipedia*](https://en.wikipedia.org/wiki/Entscheidungsproblem)

[^10-17]: [Alan Turing The Math Genius, The Cryptanalyst, and The Father Of Computer Science](https://i3l.ac.id/alan-turing-the-math-genius-the-cryptanalyst-and-the-father-of-computer-science/)
[^10-18]: [Alan Turing and the Development of the Electronic Computer](https://sites.math.rutgers.edu/~cherlin/History/Papers2002/turing.html)

[^10-19]: [Turing Machines](https://plato.stanford.edu/entries/turing-machine/)
[^10-20]: [Warren McCulloch and the British cyberneticians](http://sro.sussex.ac.uk/id/eprint/43089/1/McCullochBritCyberneticsV3-final.pdf)
[^10-21]: [Alan Turing](https://plato.stanford.edu/entries/turing/)
[^10-22]: [ON COMPUTABLE NUMBERS, WITH AN APPLICATION TO THE ENTSCHEIDUNGSPROBLEM](https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf)

[^10-23]: [LOGICAL CIRCUITS: THE INTELLECTUAL ORIGINS OF THE McCULLOCHâ€“PITTS NEURAL NETWORKS](https://eva.fing.edu.uy/pluginfile.php/103446/course/section/13184/Origins%20McCullock-Pitts.pdf)
[^10-24]: [stored-program computer](https://www.britannica.com/technology/stored-program-concept)
[^10-25]: [Von Neumann architecture in *Wikipedia*](https://en.wikipedia.org/wiki/Von_Neumann_architecture)
[^10-26]: [Universal Turing machine in *Wikipedia*](https://en.wikipedia.org/wiki/Universal_Turing_machine#Stored-program_computer)
[^10-27]: [Modern Computing: A Short History, 1945-2022](https://www.forbes.com/sites/gilpress/2022/04/26/modern-computing-a-short-history-1945-2022/?sh=104b78984332)
[^10-28]: [ENIAC in *Wikipedia*](https://en.wikipedia.org/wiki/ENIAC)
[^10-29]: [Manchester Baby in *Wikipedia*](https://en.wikipedia.org/wiki/Manchester_Baby)
[^10-30]: [The First Modern Computer â€“ The Case for Baby, the Manchester Mk I Prototype ï¼ˆComputer Historyï¼‰](https://learn.saylor.org/mod/book/view.php?id=26579&chapterid=986#:~:text=The%20first%20machine%20to%20successfully,the%20Manchester%20Mk%20I%20Prototype.)
[^10-32]: [Edmund Berkeley in *Wikipedia*](https://en.wikipedia.org/wiki/Edmund_Berkeley)
[^10-33]: [Edmund Berkeley Publishes "Giant Brains," the First Popular Book on Electronic Computers](https://historyofinformation.com/detail.php?id=674)
[^10-34]: [On Thinking Machines, Machine Learning, And How AI Took Over Statistics](https://www.forbes.com/sites/gilpress/2021/05/28/on-thinking-machines-machine-learning-and-how-ai-took-over-statistics/?sh=5c4082232513)
[^10-35]: [COMPUTING MACHINERY AND INTELLIGENCE](https://watermark.silverchair.com/lix-236-433.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAs0wggLJBgkqhkiG9w0BBwagggK6MIICtgIBADCCAq8GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM-NytuzZrWlWhWxjtAgEQgIICgD06RD-2flBuSpnZ5zhvkUVUranRo0reR_6YS2wxVWTwAjHYH3QLqxLSLneyQ2xZlz8tMDyhn6XuVOpUdWgdp5DXonoR48n1dM5uLNaPpG4BNZc3F8cVlHbe4S1KAgYkfr0yxViynRnDXb5-KhjuNJbKA-6VNvrhvBLafhDHJ7txXfLQ9FltmfAnUp9hBgx2nyljjnUqV9hHjb82uAiVVGTIJxnY8pQW6HKW5p69d9NA6qxA6hAtGkqjnTbQHsMbqDmsvxYYF-A-wnoZgIc_sGvFB34llAm49AkqyunWTb5QGsCzUQQh4i_CzweSjoxDT1IWIvA2li9cQudIUBoxX9fzWMhNOj50sQKlWTIidjz8_FgMWbUskGLRcDQWJepyhXQSuEeZUfz-5BraMpDXyyfgy4UqY0UArqrKDxxUJVwyPutXNGBNj8jCwgN3mNIK91N0y3h0YWN0zanDG1IcNQKKU6tCI1tIWEwzZBLUzCjeJ98K25rHhhmcY5qew81eCXw885NYObCvUwAEHK_m7r4YG_klfdnpQXThQyK460HdtwLpAlUd_ySQqIr7a0HVdrO9mj0ZOECzGuuM-2XZDthN_R1_oMaaKUr2VyyipgMkrdOwjonRUNsRPOavdX0W5ek8Tt9uD-HUm2OvL9LVMExA-m29kBLhS2tEXkIRO0f370BEK0s3IGuJNwBgFxDCL859vkB7iBRAyg7WsRnT0nxCLNOfvitBQrJYaGxRJDVi-OaFVZLOB5EN1SNaUlv5U_RztyJqXa9B4rvG8sbSVbY1BfZuJpEB1Rb8wFKBgsPmyAD07wHkUM3M8PvmVJOUvQh4viavLwHYLBFt576Dmec)
[^10-36]: [JOHNNIAC in *Wikipedia*](https://en.wikipedia.org/wiki/JOHNNIAC)
[^10-37]: [Logic Theorist](https://history-computer.com/logic-theorist/)
[^10-38]: [Newell, Simon & Shaw Develop the First Artificial Intelligence Program](https://www.historyofinformation.com/detail.php?id=742)
[^10-39]: [Allen Newell](https://www.britannica.com/biography/Allen-Newell)
[^10-40]: [Logic Theoristã¨æ¢ç´¢æœ¨](https://ja.unionpedia.org/c/Logic_Theorist/vs/%E6%8E%A2%E7%B4%A2%E6%9C%A8)
[^10-41]: [A brief history of AI](https://naqviasad86.wixsite.com/asadnaqvi/post/a-brief-history-of-ai)
[^10-42]: [Symbolic artificial intelligence in *Wikipedia*](https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence)
[^10-43]: [The History of Artificial Intelligence](
https://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/)
[^10-44]: [A PROPOSAL FOR THE DARTMOUTH SUMMER RESEARCH PROJECT ON ARTIFICIAL INTELLIGENCE](http://jmc.stanford.edu/articles/dartmouth/dartmouth.pdf)
[^10-45]: [Dartmouth Summer Research Project: The Birth of Artificial Intelligence](https://www.historyofdatascience.com/dartmouth-summer-research-project-the-birth-of-artificial-intelligence/)
[^10-46]: [A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence](http://jmc.stanford.edu/articles/dartmouth.html)
[^10-47]: [The MCP Neuron](https://jontysinai.github.io/jekyll/update/2017/09/24/the-mcp-neuron.html)
[^10-48]: [Donald O. Hebb in *Wikipedia*](https://en.wikipedia.org/wiki/Donald_O._Hebb)
[^10-49]: [Symbolic vs Connectionist A.I.](https://towardsdatascience.com/symbolic-vs-connectionist-a-i-8cf6b656927)
[^10-50]: [The Pioneers of AI: Marvin Minsky and the SNARC](https://zahid-parvez.medium.com/history-of-ai-the-first-neural-network-computer-marvin-minsky-231c8bd58409)
[^10-51]: Gugerty L (2006) Newell and Simonâ€™s logic theorist: historical background and impact on cognitive modelling. In: Proceedings of the human factors and ergonomics society annual meeting. Symposium conducted at the meeting of SAGE Publications. Sage, Los Angeles, CA
[^10-52]: [Hebbian Learning](https://thedecisionlab.com/reference-guide/neuroscience/hebbian-learning)
[^10-53]: [The perceptron](https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Neuron/index.html)
[^10-54]: [The History and Status of the P versus NP Question](https://dl.acm.org/doi/pdf/10.1145/129712.129771)
[^10-55]: [The Rise In Computing Power: Why Ubiquitous Artificial Intelligence Is Now A Reality](https://www.forbes.com/sites/intelai/2018/07/17/the-rise-in-computing-power-why-ubiquitous-artificial-intelligence-is-now-a-reality/?sh=548777ca1d3f)

## 1957~1980å¹´ã”ã‚: Logic-based AI
ï¼ˆæ±ºã‚ã‚‰ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¸­ã‹ã‚‰æœ€é©ãªæ–¹æ³•ã‚’æ¢ç´¢ã™ã‚‹AIï¼‰AI ã®å•é¡Œè§£æ±ºæ‰‹æ³• (ä¸»ã«æ¤œç´¢ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•)
æœ¬ç¯€ä»¥é™ã§ã¯ã€AIã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚„æŠ€è¡“ã®å¤‰é·ã«æ³¨ç›®ã™ã‚‹ãŸã‚ç™ºæ˜è€…ã‚„é–¢ä¿‚è€…ã¯å‰²æ„›ã™ã‚‹å ´åˆãŒã‚ã‚‹ã€‚
### 1st AI boom
1958å¹´ã€Connectionist AIã®åˆ†é‡ã§ã¯ã€Rosenblattã«ã‚ˆã‚ŠPerceptronã¨å‘¼ã°ã‚Œã‚‹å˜å±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒç™ºæ˜ã•ã‚ŒãŸã€‚Perceptronã¯ã€MPãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒ0ã¾ãŸã¯1ã®2ã¤ã®å€¤ã®ã¿ã‚’æ‰±ã†ã®ã«å¯¾ã—ã¦å°æ•°ç‚¹ä»¥ä¸‹ã‚’å«ã‚“ã å€¤ã‚’æ‰±ã†ã‚ˆã†ã«ãªã‚Šã€åŠ ãˆã¦Hebbç†è«–ã§å°å…¥ã•ã‚ŒãŸé‡ã¿ã‚’æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦èª¿ç¯€ã™ã‚‹ã€ã™ãªã‚ã¡å‰ç¯€ã®SNARCåŒæ§˜ã«æ©Ÿæ¢°ãŒå­¦ç¿’ã™ã‚‹æ–¹æ³•ã‚‚è€ƒæ¡ˆã•ã‚ŒãŸ[^20-4] [^20-5]ã€‚ã“ã®ã‚ˆã†ãªå­¦ç¿’æ–¹æ³•ã¯**æ•™å¸«ã‚ã‚Šå­¦ç¿’**ï¼ˆSupervised Learningï¼‰ã¨å‘¼ã°ã‚Œã€ã“ã‚Œã«å¯¾ã—ã¦æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãªã„ã“ã®é ƒä¸»æµã ã£ãŸå­¦ç¿’æ–¹æ³•ã¯**æ•™å¸«ãªã—å­¦ç¿’**ï¼ˆUnsupervised Learningï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ãã€‚
ã“ã®ã‚ˆã†ã«äººé–“ãŒãƒ«ãƒ¼ãƒ«ã‚’ä½œã‚‰ãšã«æ©Ÿæ¢°ã«å­¦ç¿’èƒ½åŠ›ã‚’ä¸ãˆã‚‹ç ”ç©¶åˆ†é‡ã«å¯¾ã—ã¦ã€1959å¹´ã«Arthur SamuelãŒ**Machine Learning**ï¼ˆ**æ©Ÿæ¢°å­¦ç¿’**ï¼‰ã¨ã„ã†è¨€è‘‰ã‚’æå”±ã—ãŸ[^20-10]ã€‚Samuelè‡ªèº«ã‚‚1952å¹´ã«[Checkers](https://ja.wikipedia.org/wiki/%E3%83%81%E3%82%A7%E3%83%83%E3%82%AB%E3%83%BC)ã‚’ãƒ—ãƒ¬ã‚¤ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œæˆã—[^20-8]ï¼ˆ[Alpha-beta pruning](https://lethediana.sakura.ne.jp/tech/archives/uncategorized-ja/2134/)ã¨å‘¼ã°ã‚Œã‚‹æ–¹æ³•ã§åŠ¹ç‡çš„ã«æˆ¦ç•¥ã‚’æ¢ç´¢ã•ã›ãŸï¼‰ã€1955å¹´ã«Rot Learningã¨å‘¼ã°ã‚Œã‚‹æ–¹å¼ã§å‹è€…ã®æˆ¦ç•¥ã‚’å­¦ç¿’å¯èƒ½ã¨ã—[^20-11]ã€1959å¹´ã«å½“æ™‚ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’æ‰“ã¡è² ã‹ã—ã¦ã„ã‚‹[^20-9]ã€‚

> **note 3**
ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ•°å­¦ãƒ¢ãƒ‡ãƒ«ã®ã“ã¨ã‚’Perceptronã¨å‘¼ã¶ã“ã¨ã‚‚ã‚ã‚Š[^10-53]ã€ãã®å ´åˆã€MPãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒæœ€åˆã®Perceptronã¨ãªã‚‹ã€‚

ãŸã ã—ã€ã“ã®æ™‚æœŸã®AIç ”ç©¶ã¯Symbolic AIã®åˆ†é‡ãŒã‚ˆã‚Šå¤§ããªç››ã‚Šä¸ŠãŒã‚Šã‚’è¦‹ã›ã¦ã„ãŸã€‚

æ§˜ã€…ãªç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹AIï¼ˆå‰ç¯€ã®Logic Theoristã®å ´åˆã€å®šç†ã®è¨¼æ˜ã¨ã„ã†ã‚¿ã‚¹ã‚¯ï¼‰ãŒãƒ¡ã‚¤ãƒ³ã ã£ãŸãŒã€1959å¹´ã«Allen Newellã¨Herbert A. Simonã«ã‚ˆã‚Š**General Problem Solver**ï¼ˆ**GPS**ï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã€ä¸€èˆ¬çš„ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹ã“ã¨ã‚’æ„å›³ã—ãŸAIãŒç™ºæ˜ã•ã‚ŒãŸ[^20-13]ã€‚GPSã¯ã€åˆ°é”ã—ãŸã„ç›®æ¨™ã¸ä¸€è¶³é£›ã³ã«ãŸã©ã‚Šç€ã‘ãªã„å ´åˆã«ã€ç›®æ¨™ã¨ã®å·®ã‹ã‚‰ä¸­é–“ç›®æ¨™ã‚’ä½œã£ã¦å¾ã€…ã«ç›®æ¨™ã«è¿‘ã¥ã[Means End Analysis](https://lethediana.sakura.ne.jp/tech/archives/summary-ja/2143/)ï¼ˆMEAï¼‰ã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’å°å…¥ã—ã¦ãŠã‚Šã€GPSä»¥å¾Œã€MEAã¯AIã«åºƒãåˆ©ç”¨ã•ã‚ŒãŸ[^20-14]ã€‚
*Forward searchã¨Backward searchã‚’çµ„ã¿åˆã‚ã›ãŸæ‰‹æ³•ãƒ»ãƒ»ãƒ»*

> **note 3**
å®Ÿéš›ã«ã¯ã€è«–ç†ã‚„å¹¾ä½•å­¦ã®å®šç†ã®è¨¼æ˜ã€Chessã®ã‚ˆã†ãªæ˜ç¢ºã«å®šç¾©ã•ã‚ŒãŸå•é¡Œã«ã®ã¿é©ç”¨å¯èƒ½ã ã£ãŸãŒã€ä»–ã®ç†è«–çš„ç ”ç©¶ã®åŸºç¤ã«ãªã£ã¦ã„ã‚‹[^20-12] ã€‚
- SOARï¼ˆ1982ï¼‰[Laird, John & Rosenbloom, Paul. (1994). The Evolution of the Soar Cognitive Architecture. ]
- GOMS

ã“ã®ã‚ˆã†ãªAIç ”ç©¶ã®æˆåŠŸã«åŠ ãˆã€1961å¹´ã«ä¸–ç•Œåˆã®ICãƒãƒƒãƒ—ãŒè²©å£²[^20-15]ï¼ˆã“ã‚Œã¾ã§ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ï¼ˆIBM704ï¼‰ãŒãƒ¡ãƒ¢ãƒªä¸è¶³ã ã£ãŸ[^20-16]ã¨ã„ã†AIç ”ç©¶ã«å¯¾ã™ã‚‹ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’å…‹æœã™ã‚‹ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®é€²åŒ–ï¼‰ã€1965å¹´ã®ãƒ ãƒ¼ã‚¢ã®æ³•å‰‡[^20-31]ã€1962å¹´ã«ARPAï¼ˆAdvanced Research Projects Agencyã€é«˜ç­‰ç ”ç©¶è¨ˆç”»å±€ï¼‰ã«IPTOï¼ˆInformation Processing Techniques Officeã€æƒ…å ±å‡¦ç†æŠ€è¡“å±€ï¼‰ã®è¨­ç«‹ã¨[^20-17]ã€ãã‚Œã«ã‚ˆã‚‹ãƒã‚µãƒãƒ¥ãƒ¼ã‚»ãƒƒãƒ„å·¥ç§‘å¤§å­¦ï¼ˆMITï¼‰ã€ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ï¼ˆSAILï¼ˆStanford Artificial Intelligence Laboratoryï¼‰ã€Stanford HPPï¼ˆHeuristics Programming Projectï¼‰ç­‰ï¼‰ã€ã‚«ãƒ¼ãƒã‚®ãƒ¼ãƒ¡ãƒ­ãƒ³å¤§å­¦ã‚’ã¯ã˜ã‚ã¨ã™ã‚‹AIç ”ç©¶ã¸ã®æŠ•è³‡ãªã©ã«ã‚ˆã‚Šã€AIç ”ç©¶ã®è¦æ¨¡ãŒæ ¹æœ¬çš„ã«å¤‰ã‚ã‚Šã€å°è¦æ¨¡ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é›†ã¾ã‚Šã‹ã‚‰å¤§è¦æ¨¡ã§æ³¨ç›®åº¦ã®é«˜ã„åˆ†é‡ã¸ã¨æ¨é€²ã•ã‚ŒãŸ[^20-18]ã€‚
1965å¹´ã«ã¯HPPã§DENDRALï¼ˆDENDRitic ALgorithmï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã€åŒ–å­¦è€…ãŒæœªçŸ¥ã®æœ‰æ©Ÿåˆ†å­ã‚’ç‰¹å®šã§ãã‚‹ã‚ˆã†ã«åˆ†å­ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æã‚’è¡Œã„æ§‹é€ ã‚’ç¤ºã™AIã®é–‹ç™ºãŒé–‹å§‹ã•ã‚ŒãŸ[^20-19]ã€‚SAILã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿PDP-6ã§ä½œæˆã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã‚ã‚Šã€åˆ†å­ã‚’æ§‹æˆã™ã‚‹åŸå­ã®æƒ…å ±ã‚„ã€æ¢ç´¢ã®å„ªå…ˆåº¦ãªã©åŒ–å­¦è€…ã®çŸ¥è­˜ã‚’ã‚ã‚‰ã‹ã˜ã‚çµ„ã¿è¾¼ã¿ã€ãã‚Œã‚‰ã‚’åˆ©ç”¨ã—ã¦è³ªé‡åˆ†æã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹[^20-21] [^20-22]ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®æ§‹æˆç­‰ã«ã¤ã„ã¦ã¯[ã“ã¡ã‚‰](https://lethediana.sakura.ne.jp/tech/archives/summary-ja/2154/)ã‚‚å‚ç…§ãã ã•ã„ï¼‰ã€‚**DENDRAL**ã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ï¼ˆã‚²ãƒ¼ãƒ ç­‰ã§ã¯ãªã„ï¼‰ç¾å®Ÿã®å•é¡Œã®ãŸã‚ã«ä½œã‚‰ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã‚ã‚‹ã¨è¨€ã‚ã‚Œã‚‹[^20-20]ã€‚æ¬¡ç¯€ã§è¿°ã¹ã‚‹ãŒã€DENDRALã¯ã“ã®å¾Œã‚‚é–‹ç™ºãŒç¶™ç¶šã•ã‚Œã‚‹ã€‚
ã¾ãŸã€1966å¹´ã«ã¯MITã®MAC time-sharingã‚·ã‚¹ãƒ†ãƒ ä¸Šã§**ELIZA**ã¨ã„ã†è‡ªç„¶è¨€èªå‡¦ç†ã®AIãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒé–‹ç™ºã•ã‚ŒãŸ[^20-25]ã€‚GUIã‚’æŒã¡ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’èªè­˜ã—ã¦äº‹å‰ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ã‚ºã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å¿œç­”ã‚’è¡Œã†ãŸã‚ã€ä¸–ç•Œåˆã®Chatbotã¨ç§°ã•ã‚Œã¦ã„ã‚‹[^20-23]ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ å†…ã§ã¯ã€If-thenãƒ«ãƒ¼ãƒ«ã‚’ç”¨ã„ãŸã€å˜ç´”ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã‚’è¡Œã£ã¦ãŠã‚Šã€è†¨å¤§ãªæ•°ã®ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’äº‹å‰ã«ç”¨æ„ã—ã¦ãŠã‹ãªã‘ã‚Œã°ãªã‚‰ãªã‹ã£ãŸãŒ[^20-24]ã€Rogerianç™‚æ³•ã®ã‚»ãƒ©ãƒ”ã‚¹ãƒˆã¨ã—ã¦å¿œå¯¾ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆDOCTORï¼‰ã§æœ‰åã«ãªã£ãŸ[^20-26] [^20-27]ã€‚

> **note 3**
ELIZAåŠ¹æœï¼ˆå‰²æ„›ï¼‰

The nearest neighbour algorithm was introduced in 1967,

ãã®ä»–ã€è‡ªã‚‰ã®è¡Œå‹•ã‚’æ¨è«–ã§ãã‚‹åˆã®æ±ç”¨ç§»å‹•ãƒ­ãƒœãƒƒãƒˆã§ã‚ã‚‹Shakey the robotã‚„[^20-28]ã€ä¸–ç•Œåˆã®Plannningã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚‹STRIPSï¼ˆSTanford Research Institute Problem Solverï¼‰ç­‰ã‚‚[^20-29] [^20-30]ã€ã“ã®é ƒã®AIã®ä¾‹ã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã‚‹ãŒã€è©³ç´°ã¯å‰²æ„›ã™ã‚‹ã€‚

### 1st AI Winter
å‰ç¯€ã®ã‚ˆã†ãªç››ã‚Šä¸ŠãŒã‚Šã‚’è¦‹ã›ãŸAIç ”ç©¶ã‚‚ã€1960å¹´ä»£å¾ŒåŠã”ã‚ã‹ã‚‰å†¬ã®æ™‚ä»£ãŒè¨ªã‚ŒãŸã€‚
Rosenblattã«ç™ºæ˜ã•ã‚ŒãŸPerceptronã¯2ç¨®é¡ã‹ã¤æ¯”è¼ƒçš„å˜ç´”ãªåˆ†é¡ã‚¿ã‚¹ã‚¯ï¼ˆå³å¯†ã«ã¯ã€ç·šå½¢åˆ†é›¢å¯èƒ½ãªã‚¿ã‚¹ã‚¯ï¼‰ã«ã—ã‹å¯¾å¿œã§ããªã„ã“ã¨ãŒã‚ã‹ã‚Š[^20-3]ã€1969å¹´ã«å‡ºç‰ˆã•ã‚ŒãŸ*Perceptrons: an introduction to computational geometry*ã¨ã„ã†æ›¸ç±ã§å˜ç´”ãªè«–ç†XORé–¢æ•°ã‚’å­¦ç¿’ã§ããªã„ã“ã¨ã‚’ç¤ºã•ã‚Œã‚‹ãªã©[^20-6]ã€éå¸¸ã«å³ã—ã„ç›®ã‚’å‘ã‘ã‚‰ã‚Œã‚‹ã“ã¨ã¨ãªã£ãŸã€‚ã¾ãŸã“ã®é ƒã®å¤šãã®ç ”ç©¶è€…ãŒã€1965å¹´é ƒã‹ã‚‰ä½¿ã‚ã‚Œã ã—ãŸ**å¼·åŒ–å­¦ç¿’**ï¼ˆtry and errorã§å­¦ç¿’ã—ã¦ã„ãæ–¹æ³•ï¼‰ã«å–ã‚Šçµ„ã‚“ã§ã„ã‚‹ã¤ã‚‚ã‚ŠãŒã€æ•™å¸«ã‚ã‚Šå­¦ç¿’ã«ãªã£ã¦ã—ã¾ã†ã‚±ãƒ¼ã‚¹ãŒå¤šç™ºã™ã‚‹ãªã©ã®æ··ä¹±ã‚‚ã‚ã‚Šã€å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ãŸç ”ç©¶ãŒå¤šããªã‹ã£ãŸ[^20-38]ã€‚John AndreaeãŒSTeLLAï¼ˆStandard Telecommunication Laboratories[^20-37]ï¼‰ã¨ã„ã†ç’°å¢ƒã‹ã‚‰trial and errorã§å­¦ç¿’ã‚’è¡Œã†ï¼ˆå¾Œã®å¼·åŒ–å­¦ç¿’ï¼‰ã‚·ã‚¹ãƒ†ãƒ ã‚’ç™ºæ˜ã—ã¦ã‚‚æ³¨ç›®åº¦ãŒä¸ŠãŒã‚‰ãªã„ãªã©[^20-36]ã€Connectionist AIã‚„æ©Ÿæ¢°å­¦ç¿’ã®åˆ†é‡ã¯ä¸‹ç«ã«ãªã£ã¦ã„ãŸã€‚
ãã—ã¦ã€1969å¹´ã®ãƒãƒ³ã‚¹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¿®æ­£æ¡ˆã«ã‚ˆã‚Šã€ARPAã®å¾Œèº«ã¨ãªã‚‹DARPAï¼ˆDefense Advanced Research Projects Agencyï¼‰ã®æŠ•è³‡å¯¾è±¡ã‚’ã€åŸºç¤ç ”ç©¶ã§ã¯ãªãå…·ä½“çš„ãªç›®çš„ã‚’ã‚‚ã£ãŸç ”ç©¶ã‚’é‡è¦–ã™ã‚‹ã‚ˆã†ã«å¤§ããå¤‰æ›´ã•ã‚ŒãŸ[^20-35]ã€‚
ãã‚Œã«åŠ ãˆã€1973å¹´ã«Science Research Councilï¼ˆã‚¤ã‚®ãƒªã‚¹ã®ç§‘å­¦ç ”ç©¶è©•è­°ä¼šï¼‰ã«å‘ã‘ã¦AIç ”ç©¶ã®è©•ä¾¡ã‚’è¡Œã£ãŸLighthill reportã§ã€èˆªç©ºæ©Ÿã®è‡ªå‹•ç€é™¸ã‚·ã‚¹ãƒ†ãƒ ãŒAIã‚ˆã‚Šã‚‚å¾“æ¥æ‰‹æ³•ã®æ–¹ãŒå„ªã‚Œã¦ã„ã‚‹ã“ã¨ã€AIãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ä½œã‚Šã“ã¿ãŒé›£ã—ã„ã“ã¨ã€çµ„ã¿åˆã‚ã›çˆ†ç™ºå•é¡ŒãŒèµ·ã“ã‚‹ã“ã¨ç­‰ã«æ³¨ç›®ã—ã€AIç ”ç©¶ã«å¯¾ã—ã¦æ‚²è¦³çš„ãªè¦‹è§£ã‚’ç¤ºã—ãŸ[^20-32] [^20-33] [^20-34]ã€‚
ã“ã®ã‚ˆã†ãªæµã‚Œã‚‚ã‚ã£ã¦è³‡é‡‘ã®ç¢ºä¿ãŒé›£ã—ããªã‚Šã€AIç ”ç©¶ã®å‹¢ã„ã¯æ¬¡ç¬¬ã«å¤±é€Ÿã—ãŸã€‚AIã¸ã®æœŸå¾…ã¯ã€äººé–“ã®è„³ã®ã‚ˆã†ãªæŸ”è»Ÿæ€§ã‚„æ±ç”¨æ€§ã‚’ã‚‚ã£ã¦ã»ã—ã„ã¨ã„ã†ç©¶æ¥µã®çŸ¥æ€§ã‚ˆã‚Šã‚‚ã€ç‰¹å®šã®åˆ†é‡ã§ã‚ã£ã¦ã‚‚ã‚ˆã‚Šç¾å®Ÿçš„ãªå•é¡Œã®è§£æ±ºã¸ã¨ç§»ã£ã¦ã„ã£ãŸã€‚

[^20-3]:[The Perceptron: A Perceiving and Recognizing Automaton (Project PARA)](https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf)
[^20-3]:[Perceptrons_book in *Wikipedia*](https://en.wikipedia.org/wiki/Perceptrons_(book))
[^20-4]:[Neural Networks: Why Does the Perceptron Rule Only Work for Linearly Separable Data?](https://saturncloud.io/blog/neural-networks-why-does-the-perceptron-rule-only-work-for-linearly-separable-data/)
[^20-5]: [The Rosenblattâ€™s Perceptron](https://maelfabien.github.io/deeplearning/Perceptron/#)
[^20-6]: [Rosenblattâ€™s perceptron, the first modern neural network](https://towardsdatascience.com/rosenblatts-perceptron-the-very-first-neural-network-37a3ec09038a)
[^20-7]: [Arthur Samuel: Pioneer in Machine Learning](https://www.researchgate.net/publication/224103556_Arthur_Samuel_Pioneer_in_Machine_Learning)
[^20-8]: [Checkers Research Page](https://www.cs.nott.ac.uk/~pszgxk/games/checkers/research.html)
[^20-9]: [The Rise and Fall of Symbolic AI](https://towardsdatascience.com/rise-and-fall-of-symbolic-ai-6b7abd2420f2)
[^20-10]: [Arthur Samuel (computer scientist) in *Wikipedia*](https://en.wikipedia.org/wiki/Arthur_Samuel_(computer_scientist))
[^20-11]: [11.2 Samuel's Checkers Player](http://incompleteideas.net/book/ebook/node109.html)
[^20-12]: [General Problem Solver (A. Newell & H. Simon)](https://www.instructionaldesign.org/theories/general-problem-solver/)
[^20-13]: [Report on a general problem-solving program](http://bitsavers.informatik.uni-stuttgart.de/pdf/rand/ipl/P-1584_Report_On_A_General_Problem-Solving_Program_Feb59.pdf)
[^20-14]: [Newell, Allen](encyclopedia.com/people/science-and-technology/computers-and-computing-biographies/allen-newell)
[^20-15]: [Vintage Computer Chip Collectibles, Memorabilia & Jewelry](https://www.chipsetc.com/fairchild-semiconductor.html)
[^20-16]: [**Building the Second Mind, 1961-1980: From the Ascendancy of ARPA to the Advent of Commercial Expert Systems**](https://escholarship.org/content/qt82h464gg/qt82h464gg_noSplash_0c64963f432723c12a0e1656888b8558.pdf?t=mnaxni)
[^20-17]: [DARPA's Impact on Artificial Intelligence](https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/5294/7228)
[^20-18]: [Developments in Artificial Intelligence](https://nap.nationalacademies.org/read/6323/chapter/11#204)
[^20-19]: [DENDRAL: a case study of the first expert system for scientific hypothesis formation](https://web.mit.edu/6.034/www/6.s966/dendral-history.pdf)
[^20-20]: [An analysis on the dendral expert system](https://www.grin.com/document/213082)
[^20-21]: [Buchanan, Bruce & Feigenbaum, E.A. & Lederberg, J.. (1968). Heuristic DENDRAL: A program for generating explanatory hypotheses in organic chemistry. Machine Intelligence. 4. ](https://www.researchgate.net/publication/23622692_Heuristic_DENDRAL_A_program_for_generating_explanatory_hypotheses_in_organic_chemistry)
[^20-22]: [DENDRAL and Meta-DENDRAL roots of knowledge systems and expert system applications](https://stacks.stanford.edu/file/druid:rv258md4469/rv258md4469.pdf)
[^20-23]: [Story of ELIZA, the first chatbot developed in 1966](https://analyticsindiamag.com/story-eliza-first-chatbot-developed-1966/)
[^20-24]: [Natural Language Processing](https://www.inf.ed.ac.uk/teaching/courses/il1/slides/19-nlp2-2011-11-15.pdf)
[^20-25]:[ELIZA A Computer Program For the Study of Natural Language Communication Between Man And Machine](https://web.stanford.edu/class/cs124/p36-weizenabaum.pdf)
[^20-26]: [ELIZA: a very basic Rogerian psychotherapist chatbot](https://web.njit.edu/~ronkowit/eliza.html)
[^20-27]: [The computational therapeutic: exploring Weizenbaumâ€™s ELIZA as a history of the present](https://link.springer.com/article/10.1007/s00146-018-0825-9)
[^20-28]: [Remembering Shakey, the First Intelligent Robot](https://thenewstack.io/remembering-shakey-first-intelligent-robot/)
[^20-29]: [Blocks World Example](http://www-formal.stanford.edu/jsierra/my-web-page/nmr-98/heuristics-ac/node2.html)
[^20-30]: [Artificial Intelligence Planning STRIPS](https://u.cs.biu.ac.il/~haimga/Teaching/AI/lessons/lesson7.pdf)
[^20-31]: [What Is Mooreâ€™s Law and How Does It Impact AI ?](https://www.unite.ai/moores-law/)
[^20-32]: [Artificial Intelligence: A General Survey](https://rodsmith.nz/wp-content/uploads/Lighthill_1973_Report.pdf)
[^20-33]:[Review of ``Artificial Intelligence: A General Survey''](https://www-formal.stanford.edu/jmc/reviews/lighthill/lighthill.html)
[^20-34]:[Lighthill report in *Wikipedia*](https://en.wikipedia.org/wiki/Lighthill_report)
[^20-35]:[Ai Winter](https://academic-accelerator.com/encyclopedia/ai-winter)
[^20-36]:[Reinforcement Learning: An Introduction](https://inst.eecs.berkeley.edu/~cs188/sp20/assets/files/SuttonBartoIPRLBook2ndEd.pdf)
[^20-37]:[1962-6 â€“ â€œSTELLAâ€ CYBERNETIC TORTOISE â€“ JOHN H. ANDREAE AND PETER L. JOYCE (BRITISH)](https://cyberneticzoo.com/cyberneticanimals/1962-6-stella-cybernetic-tortoise-john-h-andreae-and-peter-l-joyce-british/)
[^20-38]: [1.6 History of Reinforcement Learning](http://incompleteideas.net/book/ebook/node12.html)

## 1980~1993ã”ã‚ï¼šKnowledge-based AI
### 2nd AI boom
å‰è¿°ã—ãŸDENDRALã®ç ”ç©¶ã¯ã€å¯¾è±¡ã¨ã™ã‚‹åŒ–å­¦æ§‹é€ ã®æ‹¡å¤§ã‚’ç›®æŒ‡ã™Dendral Projectã€åŒ–å­¦çš„çŸ¥è­˜æ´»ç”¨ã®å‘ä¸Šã‚’ç›®æŒ‡ã™MetaDendral Projectã€ã•ã‚‰ãªã‚‹ä¸€èˆ¬åŒ–ã‚’ç›®æŒ‡ã™[Mycin](https://en.wikipedia.org/wiki/Mycin) Projectã«åˆ†åŒ–ã™ã‚‹ãªã©ã—ã¦ç¶™ç¶šã•ã‚Œã¦ã„ãŸ[^30-6]ã€‚é–‹ç™ºå½“åˆã®æ¤œç´¢ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆ* Boolean logic and logical reasoning, deterministic model*[^30-10]ï¼‰ã§å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®èƒ½åŠ›ã‚’ã‚‚ã£ãŸAIã¨ã¯ã„ã‹ãªã‹ã£ãŸãŒã€ã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒå•é¡Œè§£æ±ºã‚’è¡Œã†ãŸã‚ã«ã¯ï¼ˆå¾“æ¥é‡è¦–ã•ã‚Œã¦ã„ãŸæ¨è«–æ–¹æ³•ã‚ˆã‚Šã‚‚ï¼‰çŸ¥è­˜ãŒé‡è¦ã§ã‚ã‚‹[^30-7]ã€ã¨ã„ã†è€ƒãˆæ–¹ã«åŸºã¥ã„ã¦ãŠã‚Šã€ã“ã‚Œã¯Knowledge-is-powerä»®èª¬ï¼ˆå¾Œã®Knowledge principleï¼‰ã¨å‘¼ã°ã‚Œã‚‹[^30-5]ã€‚å°‚é–€çŸ¥è­˜ã‚’æŒã¤äººé–“ãŒExpertã¨ç§°ã•ã‚ŒãŸã“ã¨ã‹ã‚‰[^30-8]ã€ã“ã®ã‚ˆã†ãªçŸ¥è­˜ã¨å•é¡Œè§£æ±ºæ–¹æ³•ãŒåˆ†ã‘ã‚‰ã‚ŒãŸæ§‹é€ ã‚’æŒã¡ãã‚Œãã‚Œåˆ¥ã®é–‹ç™ºè€…ï¼ˆå°‚é–€çŸ¥è­˜ã‚’æŒã¤äººã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œæˆã™ã‚‹äººï¼‰ãŒæ‹…å½“ã§ãã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’**Expert System**ï¼ˆã¾ãŸã¯**Knowledge based System**ï¼‰[^30-9]ã€çŸ¥è­˜ã‚’ä½“ç³»åŒ–ã™ã‚‹å–ã‚Šçµ„ã¿ã¯Knowledge Engineeringã¨å‘¼ã°ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸ[^30-5]ã€‚ã“ã®ã‚ˆã†ãªæ§‹é€ ã‚’ã¨ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒå¿…ãšã—ã‚‚å°‚é–€çŸ¥è­˜ã‚’ç¿’å¾—ã—ãŸã‚Šã€å°‚é–€çŸ¥è­˜ã‚’æŒã¤äººãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚’ç¿’å¾—ã™ã‚‹å¿…è¦ãŒãªããªã£ãŸã“ã¨ãŒå¤§ããªåŠŸç¸¾ã®ä¸€ã¤ã¨ã„ãˆã‚‹[^30-10]ã€‚
ä¸€æ–¹ã€ã“ã®é ƒICã‚‚ç€ã€…ã¨é›†ç©åŒ–ã‚’é€²ã‚ã‚‹ã€‚1960å¹´ä»£å‰åŠã«SSIï¼ˆSmall-Scale Integrationï¼‰ãƒ¬ãƒ™ãƒ«ã€1960å¹´ä»£å¾ŒåŠã«MSIï¼ˆMedium-Scale Integrationï¼‰ãƒ¬ãƒ™ãƒ«ã€1970å¹´ä»£ä¸­ç›¤ã«ã¯LSIï¼ˆLarge-Scale Integrationï¼‰ãƒ¬ãƒ™ãƒ«ã¸ã€ãã—ã¦1971å¹´ã«åˆã®ãƒã‚¤ã‚¯ãƒ­ãƒ—ãƒ­ã‚»ãƒƒã‚µï¼ˆCentral Processing Unit: CPUã¨ã‚‚å‘¼ã°ã‚Œã‚‹ï¼‰Intel 4004ãŒç™ºæ˜ã•ã‚Œã‚‹ãªã©ã€ãƒ ãƒ¼ã‚¢ã®æ³•å‰‡é€šã‚Šé›†ç©åº¦ã‚’ä¸Šã’ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®å°å‹åŒ–ã¨è¨ˆç®—èƒ½åŠ›å‘ä¸ŠãŒé †èª¿ã«é€²ã‚“ã [^30-1] [^30-2]ï¼ˆå„ãƒ¬ãƒ™ãƒ«è©³ç´°ã¯å‰²æ„›ï¼‰ã€‚ãã‚Œã«ã‚ˆã‚ŠMinicomputerã¨å‘¼ã°ã‚Œã‚‹ä¸­è¦æ¨¡ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ï¼ˆç¾åœ¨ã®ã€Œã‚µãƒ¼ãƒãƒ¼ã€è¦æ¨¡ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ï¼‰ãŒå¸‚å ´ã«å‡ºå§‹ã‚ã‚‹ã“ã¨ã¨ãªã£ãŸ[^30-3]ã€‚Minicomputerã¯ä¼æ¥­ã§å¤§é‡ã«è³¼å…¥ã•ã‚Œã€ãã‚Œã«ã‚ˆã‚Šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå¢—åŠ ã€ãã‚Œã‚‰ã‚’æ•´ç†ãƒ»å‚ç…§ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã®éœ€è¦ãŒé«˜ã¾ã£ãŸ[^30-4]ã€‚
ã“ã®ã‚ˆã†ãªçŠ¶æ³ã®ä¸­ã€1978å¹´ã«CMUã®ç ”ç©¶è€…ãŒã€Miniconputerã®ãƒ™ãƒ³ãƒ€ãƒ¼ã§ã‚ã‚‹DECã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿æ§‹æˆæ¥­å‹™ã‚’ã‚¢ã‚·ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®XCONï¼ˆeXpert CONfiguratorï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹ç™ºã—ãŸ[^30-11]ã€‚1982å¹´ã«å°å…¥å¾Œã€å¹´ã«4000ä¸‡ãƒ‰ãƒ«ã®ã‚³ã‚¹ãƒˆãƒ€ã‚¦ãƒ³ãŒã•ã‚ŒãŸã¨ã•ã‚Œã€AIãŒç”£æ¥­ç•Œã§æœ¬æ ¼çš„ã«ç”¨ã„ã‚‰ã‚Œã‚‹ä¾‹ã¨ãªã£ãŸ[^30-12] [^30-13]ã€‚
*Forward chainã¨Backward chain*
*Decision Treeã®èµ·æº*
 decision trees (e.g.,Quinlan, 1986a) and logical concept definitions (Mitchell, 1982; Michalski, 1983)
 The nonlinear revolution of the 1980s, initiated when the introduction of back-propagation networks and decision trees opened the
possibility of efficiently learning nonlinear
decision rules, deeply influenced the evolution
of many fields, and paved the way for the creation of entire disciplines, such as data mining
and a significant part of bioinformatics
*Support Vector Machines and Kernel Methods The New Generation of Learning Machines*
AIã«å–ã‚Šçµ„ã‚€ç ”ç©¶è€…ã®é–¢å¿ƒãŒExpert Systemã«å‘ã„ã¦ã„ã‚‹ã“ã®é ƒã€ã•ã‚‰ã«è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€ã“ã‚Œã¾ã§ã®å¸¸è­˜ã§ã‚ã£ãŸSymbolã‚’ç”¨ã„ãŸæ±ºå®šè«–çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã ã‘ã§ãªãã€ä¸ç¢ºå®Ÿæ€§ãƒ»æ•°å€¤ã‚’ç”¨ã„ãŸç¢ºç‡çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚‚æ³¨ç›®ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ããŸ[^30-14] [^30-15]ã€‚åˆæœŸã®ä¾‹ã¯ã€Certainly factorã‚’ç”¨ã„ãŸMYCINï¼ˆ1975å¹´ï¼‰[^30-18]ã€Bayesã®å®šç†ã‚’ç”¨ã„ãŸPROSPECTORï¼ˆ1978https://com-cog-book.github.io/com-cog-book/features/recurrent-net.html#Learning-objectiveså¹´ï¼‰[^30-19]ã€Fuzzyè«–ç†ã‚’ç”¨ã„ãŸCADIAG-2ï¼ˆ1980å¹´ï¼‰[^30-17]ãªã©ãŒæŒ™ã’ã‚‰ã‚Œã€å®Ÿç”¨çš„ã‹ã¤çŸ¥çš„ãƒ¬ãƒ™ãƒ«ã®é«˜ã„AIã‚’ç›®æŒ‡ã—ãŸå–ã‚Šçµ„ã¿ãŒç››ã‚“ã«è¡Œã‚ã‚ŒãŸã€‚
ã“ã®ã‚ˆã†ãªExpert Systemã®ç™ºå±•ã«ä¼´ã„ã€IBMã‚’è¿½ã„è¶Šãã†ã¨æ—¥æœ¬ã®é€šå•†ç”£æ¥­çœæ‰€ç®¡ã®æ–°ä¸–ä»£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿æŠ€è¡“é–‹ç™ºæ©Ÿæ§‹ï¼ˆICOTï¼šInstitute for New Generation Computer Technologyï¼‰ã§ã€å›½å®¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦ç¬¬äº”ä¸–ä»£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ï¼ˆFGCSï¼šthe Fifth Generation Computer Systemsï¼‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¨é€²ã—[^30-21]ã€1982å¹´ã”ã‚ã‹ã‚‰4å„„ãƒ‰ãƒ«ã‚’è¶…ãˆã‚‹å¤§è¦æ¨¡ãªæŠ•è³‡ã‚’è¡Œã£ãŸ[^30-22]ã€‚ã“ã‚Œã«ä¼´ã„ã€ç±³å›½DARPAãŒSCIï¼ˆStrategic Computing Initiativeï¼‰ã‚’é–‹å§‹ã€è‹±å›½ã§ã¯Alveyãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒç™ºè¶³ã™ã‚‹ç­‰ã€FGCSã¯æµ·å¤–ã«ã‚‚å¤§ããªå½±éŸ¿ã‚’ä¸ãˆãŸ[^30-20]ã€‚
åŸºæœ¬çš„ã«ã¯Symbolic AIã®åˆ†é‡ã§Expert SystemãŒã“ã®ã‚ˆã†ãªç››ã‚Šä¸ŠãŒã‚Šã‚’è¦‹ã›ã‚‹ä¸€æ–¹ã€Connectionist AIã®åˆ†é‡ã§ã‚‚å¤§ããªé€²æ­©ãŒã‚ã£ãŸã€‚
Perceptropã‚’æŒã¡ã„ãŸéšå±¤å‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‚’ç”¨ã„ãŸAIã¯ã€1979å¹´ã«Neocognitronã¨å‘¼ã°ã‚Œã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒè€ƒæ¡ˆã•ã‚Œã€æ‰‹æ›¸ãæ–‡å­—ã®èªè­˜ã‚’æˆåŠŸã•ã›ãŸã“ã¨ã§ã€AIã«ã‚ˆã‚‹ç”»åƒã®ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸ[^30-23]ã€‚Neocognitronã¯ã€ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚¤ãƒ³ãƒ‰ã‚¦å‡¦ç†ã‚’ç”¨ã„ã¦ã€ç”»åƒã®ä¸­ã®ä½ç½®ã«é–¢ã‚ã‚‰ãšãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã™ã‚‹ã“ã¨ã®ã§ãã‚‹æ§‹é€ ã§ã‚ã‚Š[^30-24] [^30-25]ã€å¾Œã®Convolution Neural Networkï¼ˆCNNã€ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã«éå¸¸ã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã¨ãªã‚‹ã€‚
ã¾ãŸã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒç›¸äº’æ¥ç¶šã™ã‚‹æ§‹é€ ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚‚ã“ã®é ƒç™ºæ˜ã•ã‚Œã‚‹ã€‚1982å¹´ã®Hopfield networkã¯ã€å¼·ç£æ€§ä½“ã«ã‚ˆã‚‹ç£å ´ã®èª¬æ˜ã«ç”¨ã„ã‚‰ã‚Œã‚‹Isingãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦è€ƒæ¡ˆã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§[^30-27]ã€0ã¾ãŸã¯1ã‚’å‡ºåŠ›ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒç›¸äº’ã«æ¥ç¶šã•ã‚Œã¦ãŠã‚Šã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜æ†¶ã—ã¦ãã®æƒ…å ±ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹[^30-26]ã€‚å®Ÿéš›ã«ã¯è¨ˆç®—åŠ¹ç‡ãŒæ‚ªãéç¾å®Ÿçš„ã§ã‚ã£ãŸãŒã€å¾Œã®Recurrent Neural Networkã«å¤§ããªã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¸ãˆãŸ[^30-28]ã€‚ã¾ãŸ1985å¹´ã«ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å‡ºåŠ›ã‚’ç¢ºç‡çš„ã«ã—ãŸåˆ¶é™ä»˜ããƒœãƒ«ãƒ„ãƒãƒ³ãƒã‚·ãƒ³ãŒç™ºæ˜ã•ã‚Œã¦ã„ã‚‹[^30-30]ã€‚
ãã—ã¦æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®æ–¹æ³•ã«ã†ã„ã¦ã€1986å¹´ã«David Rumelhartã€Geoffrey Hintonã€Ronald Williamsã®è«–æ–‡[^30-31]ã§ç™ºè¡¨ã•ã‚ŒãŸ**BP**ï¼ˆ**Backpropagationã€èª¤å·®é€†ä¼æ¬**ï¼‰**æ³•**ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚BPæ³•ã«ã‚ˆã‚Šã€æ•™å¸«ã‚ã‚Šå­¦ç¿’ã«ãŠã„ã¦æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‡ºåŠ›ã®èª¤å·®ã‚’ã€é€†ä¼æ¬ã•ã›ã¦ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒæŒã¤ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã™ã‚‹ï¼ˆèª¤å·®ãŒå¤§ãã„ã»ã©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤§ããèª¿æ•´ã™ã‚‹ï¼‰ã“ã¨ãŒã§ã[^30-32]ã€åºƒãä½¿ã‚ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸï¼ˆBPæ³•ã®åŸºæœ¬ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒç™ºæ˜ã•ã‚ŒãŸã®ã¯å³å¯†ã«ã¯1961å¹´ã¨ã•ã‚Œã‚‹ãŒè©³ç´°ã¯å‰²æ„›ï¼‰[^30-33]ã€‚
åŒ1986å¹´ã€NETTalkã¨ã„ã†æ–‡å­—ã‹ã‚‰éŸ³ç´ ï¼ˆéŸ³ã®æœ€å°å˜ä½ï¼‰ã¸ã®å¤‰æ›ãŒå¯èƒ½ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒç™ºè¡¨ã•ã‚ŒãŸã€‚å¾Œã®ä¸€èˆ¬çš„ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚ˆã†ã«å…¥åŠ›å±¤-éš ã‚Œå±¤-å‡ºåŠ›å±¤ã¨ã„ã†3å±¤ã®æ§‹é€ ã‚’æŒã¡ã€å­¦ç¿’æ–¹æ³•ã«ã¯BPæ³•ã¨*************ï¼ˆå‹¾é…é™ä¸‹æ³•ã€‚å‹¾é…é™ä¸‹ç­‰ã®æ­´å²ã«ã¤ã„ã¦ã‚‚è¦èª¿æŸ»ï¼‰ãŒç”¨ã„ã‚‰ã‚Œ[^30-29]ã€è‹±èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ä¸Šã’ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚åŒæ§˜ã®ã‚¿ã‚¹ã‚¯ã«Expert Systemã§å–ã‚Šçµ„ã¿ï¼ˆèª­ã¿ä¸Šã’ç²¾åº¦ã¯é«˜ã„ã‚‚ã®ã®ï¼‰æ•°å¹´é–“ã‹ã‹ã£ãŸDECtalkã¨æ¯”ã¹ã¦ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã¯é–‹ç™ºæœŸé–“ãŒçŸ­ã„ã“ã¨ã‚’ç¤ºã—ãŸ[^30-34]ã€‚
*Christopher Watkins developed a Q-learning algorithm*

### 2nd AI Winter
1980å¹´ä»¥é™ã«æœŸå¾…ã•ã‚ŒãŸExpert Systemã¯ã€å®Ÿã¯1984å¹´ã«AIã®å…ˆé§†è€…ã§ã‚ã‚‹John McCarthyã«æ‰¹åˆ¤ã•ã‚Œã¦ã„ã‚‹ã€‚ä¸»ãªæ‰¹åˆ¤å†…å®¹ã¯ã€Expert Systemã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ å¤‰æ›´ãŒå®¹æ˜“ã§ãªãå¤‰åŒ–ã«å¯¾å¿œã—ã¥ã‚‰ã„ã“ã¨ã€äººãŒå½“ãŸã‚Šå‰ã«æŒã£ã¦ã„ã‚‹å¸¸è­˜çš„ãªçŸ¥è­˜ã‚’AIãŒæŒã£ã¦ã„ãªã„ãŸã‚æ„æ€æ±ºå®šãŒä¸é©åˆ‡ã«ãªã‚Šã†ã‚‹ã“ã¨ã€ã®2ã¤ã§ã‚ã‚‹[^30-37]ã€‚ã•ã‚‰ã«ã€å®Ÿéš›ã«å°‚é–€å®¶ã®çŸ¥è­˜ã‚’ãƒ«ãƒ¼ãƒ«åŒ–ã™ã‚‹ã“ã¨ãŒéå¸¸ã«é›£ã—ã„å ´åˆãŒç›®ç«‹ã£ã¦ããŸ[^30-39]ã€‚ã™ãªã‚ã¡ã€Expert systemã¯æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨ãƒ«ãƒ¼ãƒ«åŒ–å¯èƒ½ãªè«–ç†ãŒã‚ã£ã¦åˆã‚ã¦å¯èƒ½ã§ã‚ã‚Šã€è‡ªç„¶è¨€èªã‚„ç”»åƒç­‰ã®ï¼ˆæ›–æ˜§ãªï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šæ‰±ã†ã“ã¨ãŒå›°é›£ã ã£ãŸ[^30-49]ã€‚1987å¹´ã‹ã‚‰1989å¹´ã«ã‹ã‘ã¦DARPAã®ISTO (Information Science and Technology Office)ã«ã¯ã€Expert systemãŒéå¸¸ã«é™å®šçš„ãªé ˜åŸŸã§ã—ã‹æˆåŠŸã—ã¦ã„ãªã„ã€ã¨çµè«–ä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹[^30-38]ã€‚
ã¾ãŸã€ãƒã‚¤ã‚¯ãƒ­ãƒ—ãƒ­ã‚»ãƒƒã‚µãŒé–‹ç™ºã•ã‚Œã¦ã‹ã‚‰å€‹äººã§åˆ©ç”¨ã™ã‚‹PCï¼ˆPersonal Computerï¼‰ãŒä½ã‚³ã‚¹ãƒˆåŒ–ã—ã¦ã„ã£ãŸ[^30-46]ã€‚ãã‚Œã«ä¼´ã„ã€1987å¹´ã¾ã§ã«Cè¨€èªç­‰ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«è¨€èªã‚’æ‰±ã†OSã‚’æ­è¼‰ã—ãŸAppleã‚„IBMã®PCãŒæµé€šã—ã€å¤šãã®Expert SystemãŒå®Ÿè¡Œã•ã‚Œã¦ã„ãŸLISPãƒã‚·ãƒ³ã®ãã‚Œã‚’ä¸Šå›ã£ãŸã«ã‚‚é–¢ã‚ã‚‰ãšã€ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«è¨€èªã«Expert systemã®é–‹ç™ºã«ãƒãƒƒãƒã—ãªã‹ã£ãŸã¨ã•ã‚Œã¦ã„ã‚‹[^30-39]ã€‚
*ãªãœExpert systemé–‹ç™ºãŒã‚³ãƒ³ãƒ‘ã‚¤ãƒ«è¨€èªã¨ãƒãƒƒãƒã—ãªã‹ã£ãŸã®ã‹*
ãã—ã¦1980å¹´ä»£å¾ŒåŠã‹ã‚‰ã€ç‰¹ã«æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®æ€§èƒ½ãŒæ³¨ç›®ã•ã‚Œã¦ããŸãŒã€æ•™å¸«ãƒ‡ãƒ¼ã‚¿ãŒååˆ†ã«ã¨ã‚Œãªã„ã“ã¨ã‚„[^30-43]ã€BPæ³•ã«ã‚ˆã‚‹å­¦ç¿’ã«æ™‚é–“ãŒã‹ã‹ã‚‹ç‚¹ãŒå•é¡Œã¨ã—ã¦èªè­˜ã•ã‚Œ[^30-42]ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®æ€§èƒ½å‘ä¸ŠãŒæœŸå¾…ã•ã‚ŒãŸã€‚
ã¾ãŸæœ€é©åŒ–ã®å•é¡Œç‚¹ã¨ã—ã¦ã€è¤‡é›‘ãªå‡¦ç†ã«å¯¾å¿œã—ã‚ˆã†ã¨ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¤šå±¤ã«ã™ã‚Œã°ã™ã‚‹ã»ã©ã€æå¤±é–¢æ•°ã®å‹¾é…ãŒæŒ‡æ•°é–¢æ•°çš„ã«å¤‰åŒ–ã™ã‚‹ãŸã‚ã€0ã«è¿‘ã¥ãã‚„ã™ããªã‚ŠBPæ³•ã§ã®å­¦ç¿’ãŒå›°é›£ã«ãªã‚‹ï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®é‡ã¿ãŒæ›´æ–°ã•ã‚Œãªã„ï¼‰ã¨ã„ã†å•é¡Œï¼ˆå‹¾é…æ¶ˆå¤±å•é¡Œï¼‰ãŒ1991å¹´ã«æå”±ã•ã‚Œ[^30-40] [^30-41]ã€é€†ã«ç„¡é™å¤§ã«ç™ºæ•£ã—ã¦ã—ã¾ã„å­¦ç¿’ãŒå›°é›£ã«ãªã‚‹å•é¡Œï¼ˆå‹¾é…çˆ†ç™ºå•é¡Œï¼‰ãŒ1994å¹´ã«æå”±ã•ã‚ŒãŸ[^30-44] [^30-45]ã€‚
çµŒæ¸ˆçš„ã«ã‚‚1987å¹´ã«DARPAã¯AIã«å¯¾ã™ã‚‹æŠ•è³‡ã‚’ä¸­æ­¢[^30-13]ã€1992å¹´ã«ç›®æ¨™ã‚’ã»ã¨ã‚“ã©é”æˆã™ã‚‹ã“ã¨ãªãFGCSã¯æ­£å¼ã«çµ‚äº†ã—ã¦ãŠã‚Š[^30-47]ã€ç ”ç©¶è€…ã¯å­¦è¡“ç•Œã‚„ä¼æ¥­ã‹ã‚‰ã®æ’æ–¥ã‚’æã‚Œã¦ã€æ„å›³çš„ã«AIã¨ã„ã†ç”¨èªã®ä½¿ç”¨ã‚’é¿ã‘ã¯ã˜ã‚ãŸï¼ˆä»£ã‚ã‚Šã«ã€æ©Ÿæ¢°å­¦ç¿’ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã€Intelligent Systemã€Big Dataã€Data scienceã¨ã„ã£ãŸå˜èªã‚’åˆ©ç”¨ã—ãŸï¼‰[^30-48]ã€‚

[^30-1]: [Mooreâ€™s Law and Exponential Growth](https://pdhacademy.com/wp-content/uploads/2022/01/Moores-Law-and-Exponential-Growth-course-for-website.pdf)
[^30-2]: [HISTORY OF INTEGRATED CIRCUIT OR IC](https://pijaeducation.com/basic-electronics/embedded-system/history-of-integrated-circuit-ic/)
[^30-3]: [Minicomputers: history, characteristics, uses, examples](https://warbletoncouncil.org/minicomputadoras-14120)
[^30-4]: [History of artificial intelligence: expert systems and AI winters](https://blog.pigro.ai/en/expert-systems)
[^30-5]: [Expert systems](https://dl.acm.org/doi/pdf/10.5555/1074100.1074389)
[^30-6]: [Dendral and Meta-Dendral](https://stacks.stanford.edu/file/druid:xp200rt1512/xp200rt1512.pdf)
[^30-7]: [Feigenbaum, E. A. â€œThe Art of Artificial Intelligence: Themes and Case Studies of Knowledge Engineering,â€ Proceedings of the International Joint Conference on Artificial Intelligence. Cambridge, MA: MIT Press.]
[^30-8]: [Feigenbaum, E. A., Buchanan, B. G., and Lederberg, J. â€œOn Generality and Problem Solving: A Case Study Using the DENDRAL Program,â€ in Machine Intelligence]
[^30-9]: [EXPERT SYSTEMS ](https://www.eolss.net/sample-chapters/c15/E6-44-03-04.pdf)
[^30-10]: [Jerry Kaplan, Artificial Intelligence: What Everyone Needs to Know]()
[^30-11]:[XCON](https://aithefuture.wordpress.com/2018/05/08/xcon/)
[^30-12]:[History of Artificial Intelligence (AI) and How it has evolved](https://kusham1998.medium.com/history-of-artificial-intelligence-ai-and-how-it-has-evolved-3d7607e1fff8#)
[^30-13]: [AI History: the 1980s and expert systems](https://www.klondike.ai/en/ai-history-the-1980s-and-expert-systems/)
[^30-14]: [Probability Judgment in Artificial Intelligence and Expert Systems](https://projecteuclid.org/journals/statistical-science/volume-2/issue-1/Probability-Judgment-in-Artificial-Intelligence-and-Expert-Systems/10.1214/ss/1177013426.full)
[^30-15]: [The place of fuzzy logic in AI](https://hal.science/hal-04013770/document)
[^30-16]: [Bayesian Analysis in Expert Systems](https://projecteuclid.org/journals/statistical-science/volume-8/issue-3/Bayesian-Analysis-in-Expert-Systems/10.1214/ss/1177010888.full)
[^30-17]:[CADIAG: APPROACHES TO COMPUTER-ASSISTED MEDICAL DIAGNOSIS](https://www.meduniwien.ac.at/kpa/publications/1985_CIBAM_--_CADIAG_-_Approaches_to_Computer-Assisted_Medical_Diagnosis.pdf)
[^30-18]: [A Model of Inexact Reasoning in Medicine](https://stacks.stanford.edu/file/druid:ts764ph5106/ts764ph5106.pdf)
[^30-19]: [PROSPECTOR: A Computer-Based Consultation System For Mineral Exploration](https://www.sri.com/publication/artificial-intelligence-pubs/prospector-a-computer-based-consultation-system-for-mineral-exploration/)
[^30-20]: [ç¬¬äº”ä¸–ä»£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‹ã‚‰è€ƒãˆã‚‹ AI ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ](https://www.jstage.jst.go.jp/article/jjsai/29/2/29_115/_pdf)
[^30-21]: [ç¬¬äº”ä¸–ä»£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ in *Wikipedia*](https://ja.wikipedia.org/wiki/%E7%AC%AC%E4%BA%94%E4%B8%96%E4%BB%A3%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF)
[^30-22]: [Artificial Intelligence in Japan (R&D, Market and Industry Analysis)](https://www.eu-japan.eu/sites/default/files/artificial_intelligence_in_japan.pdf)
[^30-23]: [å¤šå±¤ç¥çµŒå›è·¯ãƒã‚ªã‚³ã‚°ãƒ‹ãƒˆãƒ­ãƒ³ã®å­¦ç¿’](https://www.jstage.jst.go.jp/article/fss/30/0/30_318/_pdf)
[^30-24]: [A Brief History of Deep Learning](https://www.dataversity.net/brief-history-deep-learning/)
[^30-25]: [ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯](https://ml4a.github.io/ml4a/jp/convnets/)
[^30-26]: [Neural networks and physical systems with emergent collective computational abilities](https://www.pnas.org/doi/epdf/10.1073/pnas.79.8.2554)
[^30-27]: [Hopfield Networks: Neural Memory Machines](https://towardsdatascience.com/hopfield-networks-neural-memory-machines-4c94be821073)
[^30-28]: [Computation by neural networks](https://www.nature.com/articles/nn1100_1170)
[^30-29]:[NETtalk: a parallel network that learns to read aloud](https://papers.cnl.salk.edu/PDFs/NETtalk_%20A%20Parallel%20Network%20That%20Learns%20to%20Read%20Aloud%201988-3562.pdf)
[^30-30]: D. H. Ackley, G. E. Hinton, and T. J. Sejnowski. A learning algorithm for Boltzmann machines. Cognitive Science, pages 147â€“169, 1985.
[^30-31]: [Learning representations by back-propagating errors](https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf)
[^30-32]: [Solving the Mystery of Backpropagation](https://towardsdatascience.com/solving-the-mystery-of-backpropagation-73b18cae8e40)
[^30-33]:[Back Propagation in Neural Network: Machine Learning Algorithm](https://www.guru99.com/backpropogation-neural-network.html)
[^30-34]:[5.3 Applications 5.3.1 NETtalk](https://neuron.eng.wayne.edu/tarek/MITbook/chap5/5_3.html)
[^30-35]:[LeNet: æœ€åˆã®CNNæ§‹é€ ](https://cvml-expertguide.net/terms/dl/cnn/cnn-backbone/lenet/)
[^30-36]:[Backpropagation Applied to Handwritten Zip Code Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf)
[^30-37]:[SOME EXPERT SYSTEM NEED COMMON SENSE](https://www-formal.stanford.edu/jmc/someneed/someneed.html)
[^30-38]:[History of the Second AI Winter](https://towardsdatascience.com/history-of-the-second-ai-winter-406f18789d45)
[^30-39]:[AI Watch Historical Evolution of Artificial Intelligence](https://publications.jrc.ec.europa.eu/repository/bitstream/JRC120469/jrc120469_historical_evolution_of_ai-v1.1.pdf)
[^30-40]:[Gradient amplification: An efficient way to train deep neural networks](https://ieeexplore.ieee.org/document/9142152)
(https://ml.jku.at/publications/older/ch7.pdf)
[^30-41]:[The Vanishing Gradient Problem](https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484)
[^30-42]:[Symbolic and Neural Learning Algorithms: An Experimental Comparison](https://link.springer.com/content/pdf/10.1023/A:1022602303196.pdf)
[^30-43]:[THE IMPACT OF ARTIFICIAL INTELLIGENCE ON THE FUTURE OF WORKFORCES IN THE EUROPEAN UNION AND THE UNITED STATES OF AMERICA](https://www.whitehouse.gov/wp-content/uploads/2022/12/TTC-EC-CEA-AI-Report-12052022-1.pdf)
[^30-44]:[Exploding gradient problem](https://golden.com/wiki/Exploding_gradient_problem)
[^30-45]:[Learning long-term dependencies with gradient descent is difficult](http://www.comp.hkbu.edu.hk/~markus/teaching/comp7650/tnn-94-gradient.pdf)
[^30-46]:[History of personal computers in *Wikipedia*](https://en.wikipedia.org/wiki/History_of_personal_computers)
[^30-47]: [2 AI winters and 1 hot AI summer](https://www.entefy.com/blog/2-ai-winters-and-1-hot-ai-summer/)
[^30-48]:[TWO WINTERS AND A SPRING OF ARTIFICIAL INTELLIGENCE](https://medium.com/qed-software/two-winters-and-a-spring-of-artificial-intelligence-71a9901df77d)
[^30-49]:[The History of Artificial Intelligence from the 1950s to Today: The Emergence of NLPs and Computer Vision in the 1990s](https://www.freecodecamp.org/news/the-history-of-ai/#the-emergence-of-nlps-and-computer-vision-in-the-1990s)

## 1993~2012å¹´ã”ã‚ï¼šMachine Learning
å‰è¿°ã—ãŸExpert SystemãŒå›°é›£ã ã£ãŸéæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã€éç·šå½¢ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šæ‰±ã†ãŸã‚ã€æ©Ÿæ¢°å­¦ç¿’ãŒã‚ˆã‚Šæ³¨ç›®ã•ã‚Œå§‹ã‚ã‚‹ã€‚ãŸã ã—æ©Ÿæ¢°å­¦ç¿’ç ”ç©¶ãŒç››ã‚Šä¸ŠãŒã£ãŸåˆæœŸã¯ã€ä¿¡é ¼æ€§ã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªããƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒªã‚½ãƒ¼ã‚¹ã®é™ç•Œã‚‚ã‚ã‚Šç ”ç©¶ã®å†ç¾æ€§ãŒã¨ã‚Œãªã„ã“ã¨ã€å‡ºåŠ›ã®èª¬æ˜æ€§ãŒä¹ã—ã„ã“ã¨ãªã©ã‹ã‚‰ã€æ¯”è¼ƒçš„æ•™å¸«ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªãã¦ã‚‚æ€§èƒ½ã‚’ç™ºæ®ã—ã€ç†è«–ä¿éšœãŒå¯èƒ½ãªæ•°å­¦ãƒ»çµ±è¨ˆçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒä¸»æµã ã£ãŸ[^40-1] [^40-2] [^40-3]ã€‚
ä¾‹ãˆã°è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆNLP: Natural Language Processingï¼‰ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã¯ã€1990å¹´ä»£ã«**N-gramè¨€èªãƒ¢ãƒ‡ãƒ«**ã¨å‘¼ã°ã‚Œã‚‹ã€æ–‡ç« å†…ã§æ¬¡ã«ã©ã®å˜èªãŒãã‚‹ã‹ã®ç¢ºç‡ã‚’è¡¨ã—ãŸã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ãŒã€æ©Ÿæ¢°ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ã§ä¸€èˆ¬çš„ã«ãªã‚Šã€ãã®å¾ŒNLPã®ä»–ã®åˆ†é‡ã«ã‚‚æ‹¡å¼µã•ã‚ŒãŸã“ã¨ã¨åˆã‚ã›ã¦[^40-4]ã€ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†ã®ã«é•·ã‘ã¦ã„ã‚‹**éš ã‚Œãƒãƒ«ã‚³ãƒ•ãƒ¢ãƒ‡ãƒ«**ï¼ˆ**HMMs: Hidden Markov Models**ï¼‰ãŒåºƒãåˆ©ç”¨ã•ã‚ŒãŸ[^40-5]ã€‚ä¾‹
ãã—ã¦ã€ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ãƒ»åˆ†é¡ãƒ»å›å¸°ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã¯ã€éç·šå½¢ãƒ‡ãƒ¼ã‚¿è§£æã®æ‰‹æ³•ã§ã‚ã‚‹ã‚«ãƒ¼ãƒãƒ«æ³•ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦1992å¹´ã«**ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ãƒˆãƒ«ãƒã‚·ãƒ³**ï¼ˆ**SVM: Support Vector Machine**ï¼‰ãŒææ¡ˆã•ã‚ŒãŸ[^40-6]ã€‚SVMã¯ãƒ‡ãƒ¼ã‚¿ã‚’ï¼ˆåŸºæœ¬çš„ã«ã¯2ã¤ã®ï¼‰ã‚¯ãƒ©ã‚¹ã«åˆ†é¡ã™ã‚‹ã¨ãã€å¯èƒ½ãªé™ã‚Šå„ã‚¯ãƒ©ã‚¹ãŒå¤§ããåˆ†é›¢ã•ã‚Œã‚‹ã‚ˆã†ãªå¹³é¢ï¼ˆMMSH: Maximum Margin Separating Hyperplaneï¼‰ã‚’è¦‹ã¤ã‘ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚ã‚Š[^40-7]ã€æ¯”è¼ƒçš„ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ãå°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å‘ã„ã¦ã„ãŸãŸã‚ã€æ‰‹æ›¸ãæ–‡å­—ç”»åƒã®èªè­˜ç­‰ã«ç”¨ã„ã‚‰ã‚ŒãŸ[^40-8] [^40-9]ã€‚ä¾‹
In 1995, Dana Cortes and Vladimir Vapnik developed the support vector machine (a system for mapping and recognizing similar data)

> **note**


ä¸€æ–¹ã§å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„å¼·åŠ›ãªã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒªã‚½ãƒ¼ã‚¹ãŒå¿…è¦ã§ã‚ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åˆ†é‡ã¯ã€1994å¹´ã«MNISTï¼ˆModified National Institute of Standards and Technologyï¼‰ã¨ã„ã†å­¦ç¿’ç”¨ã«6ä¸‡ã€ãƒ†ã‚¹ãƒˆç”¨ã«1ä¸‡æšã®æ‰‹æ›¸ãæ•°å­—ç”»åƒã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä½œæˆã•ã‚Œ[^40-13]ã€ç¿Œ1995å¹´ã«LeNetã¨å‘¼ã°ã‚Œã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æœ‰ã™ã‚‹AIãŒæ‰‹æ›¸ãæ•°å­—ç”»åƒã®åˆ†é¡ç²¾åº¦ã«ãŠã„ã¦ã€SVMã‚’å«ã‚€ãã®ä»–ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®çµæœã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸ[^40-15]ï¼ˆLeNetã®ç ”ç©¶ã¯1989å¹´ã”ã‚ã‹ã‚‰å§‹ã¾ã£ã¦ã„ãŸ[^30-36]ï¼‰ã€‚LeNetã¯CNNæ§‹é€ ã‚’ã‚‚ã£ã¦ãŠã‚Šã€ç•³ã¿è¾¼ã¿å‡¦ç†ã«å­¦ç¿’å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚‚ãŸã›ã‚‹ã“ã¨ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»è¨ˆç®—ã®å‰Šæ¸›ã«æˆåŠŸã—ãŸç‚¹ãŒé‡è¦ã§ã‚ã‚Šã€ä»Šå¾Œã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç ”ç©¶ã®åŸºç›¤ã¨ãªã£ã¦ã„ã‚‹[^40-14]ã€‚
ãã—ã¦ã“ã®1995å¹´ã«ã¯ã€Windows95ãƒ»Internet Explorerã®ç™ºè¡¨ã«ã‚ˆã‚ŠPCã¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆãŒå¤šãã®äººã®èº«è¿‘ã«å±Šã„ãŸã“ã¨ã§[^40-16] [^40-17]ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãŒæƒ…å ±ã‚’å¾—ã‚„ã™ããªã‚Šã€å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å…±æœ‰ã‚‚ç¾å®Ÿçš„ãªã‚‚ã®ã«ãªã£ãŸã€‚
CNNã®ä»–ã«ã‚‚ã€Hopfield networkã‚’æ‹¡å¼µã—ãŸ[^40-18]ã€**LSTM**ï¼ˆLong-Short Time Memoryï¼‰ã¨å‘¼ã°ã‚Œã‚‹RNNãŒ1997å¹´ã«ç™ºè¡¨ã•ã‚ŒãŸã€‚LSTMã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†…ã«Memoryã‚»ãƒ«ã¨å‘¼ã°ã‚Œã‚‹å˜ä½ã§ã€æƒ…å ±ã®è¨˜æ†¶ã¨å¿˜å´ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€RNNã§å•é¡Œã¨ãªã£ã¦ã„ãŸå‹¾é…çˆ†ç™ºã‚’è§£æ±ºã—ãŸ[^40-20] [^40-21]ã€‚ã•ã‚‰ã«ã€GNNï¼ˆGraph Neural Networkï¼‰ã¨ã„ã†[ã‚°ãƒ©ãƒ•](https://lethediana.sakura.ne.jp/tech/archives/summary-ja/1367/)ã‚’å…¥å‡ºåŠ›ã¨ã™ã‚‹ãƒªãƒƒãƒãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«æ©Ÿæ¢°å­¦ç¿’ã‚’ç”¨ã„ã‚‹æ§‹é€ ãŒç™ºè¡¨ã•ã‚ŒãŸ[^40-58] [^40-59]ã€‚

> **note**
LSTMã®å…ƒè«–æ–‡ã«ã¯ãƒ¡ãƒ¢ãƒªãƒ¼ã‚»ãƒ«ãŒæƒ…å ±ã‚’forgetã™ã‚‹ã¨ã¯æ›¸ã‹ã‚Œã¦ã„ãªã„[^40-19]

ãã—ã¦ã€

In 1998, Leo Breiman formulated AdaBoost as a gradient descent 
Taking this further, Jerome Friedman, in 1999, came up with the generalisation of boosting algorithms, and thus, a new method: Gradient Boosting Machines. 

AIç ”ç©¶ã¯é‚é€²ã—ã¦ã„ãŸã€‚
ãã®é ƒä¸–é–“ã§ã‚‚ã€1997å¹´ã«IBMç¤¾ã®Deep BlueãŒãƒã‚§ã‚¹ã®ä¸–ç•Œãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ã«å‹åˆ©ã—ãŸã‚Š[^40-22]ã€AIã‚’æ­è¼‰ã—ãŸè£½å“ã§ã‚ã‚‹SONYç¤¾ã®AIBOï¼ˆArtificial Interigence roBOtã€1999å¹´ï¼‰[^40-10] [^40-11]ã€iRobotç¤¾ã®Roombaï¼ˆ2002å¹´ï¼‰[^40-12]ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã‚‹ç­‰ã€AIã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå‡ºå§‹ã‚ã¦ã„ãŸã€‚ã¾ãŸã€2001å¹´ã«ITèª¿æŸ»ä¼šç¤¾ã®META Groupç¤¾ï¼ˆ2005å¹´ã«Gartnerç¤¾ã«è²·åã•ã‚Œã¦ã„ã‚‹[^40-23]ï¼‰ãŒ**Big Data**ã‚’æå”±ã—[^40-24]ã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ç¯„å›²ãŒå¤§å¹…ã«å¢—åŠ ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦æ–°ã—ã„æ´å¯Ÿã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œ[^40-25]ã€2002å¹´ã«ã¯C/C++ã®æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªTorchãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã‚‹ãªã©[^40-26]ã€AIã®æ´»èºãƒ»é€²åŒ–ãŒã¾ã™ã¾ã™æœŸå¾…ã•ã‚ŒãŸã€‚
ãŸã ã—ã€éš ã‚Œå±¤ã®å¤šã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯**DNN**ï¼ˆDeep Neural Networkï¼‰ã¨å‘¼ã°ã‚Œ[^40-32]ã€ã‚ˆã‚Šè¤‡é›‘ãªéç·šå½¢é–¢ä¿‚ã‚’è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã¦è¡¨ç¾ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã¨æœŸå¾…ã•ã‚ŒãŸãŒ[^40-31]ã€ä¾ç„¶ã¨ã—ã¦å­¦ç¿’ãŒé›£ã—ã„ï¼ˆå‹¾é…æ¶ˆå¤±å•é¡Œã€å±€æ‰€æœ€é©åŒ–ç­‰ï¼‰ã¨ã•ã‚Œã€éš ã‚Œå±¤ã¯1å±¤ã¾ãŸã¯2å±¤ã¨ã„ã†ã®ãŒå®šçŸ³ã ã£ãŸ[^40-29]ã€‚ãã‚“ãªä¸­ã€2006å¹´ã®Geoffrey Hintonã¨Ruslan Salakhutdinovã®è«–æ–‡ã§Autoencoderã‚’æŒã¡ã„ãŸæ¬¡å…ƒå‰Šæ¸›ã®æ–¹æ³•ãŒç¤ºã•ã‚Œ[^40-30]ã€DNNã‚’åˆ†é¡ã‚¿ã‚¹ã‚¯ã«é©ç”¨ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã«ãªã£ãŸ[^40-33]ã€‚ã“ã‚Œä»¥é™ã€**Deep Learning**ã¨ã„ã†ç”¨èªãŒä¸€èˆ¬çš„ã¨ãªã‚Šã€ã‚ˆã‚Šæ³¨ç›®ã‚’æµ´ã³ã¦ã„ãã“ã¨ã¨ãªã‚‹[^40-27] [^40-28]ã€‚

> **note**
Auto encoderã¨åˆ¶é™ä»˜ããƒœãƒ«ãƒ„ãƒãƒ³ãƒã‚·ãƒ³

ã•ã‚‰ã«ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è‡ªä½“ã ã‘ã§ãªãã€ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚Šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç²¾åº¦ãŒé«˜ã¾ã‚‹ã¨ã„ã†è€ƒãˆã®ã‚‚ã¨ã€2009å¹´ã«ç‰©ä½“èªè­˜ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ç ”ç©¶ã®ãŸã‚ImageNetã¨ã„ã†å¤§è¦æ¨¡ãªç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒç™ºè¡¨ã•ã‚Œ[^40-34] [^40-35]ã€ç¿Œ2010å¹´ã‹ã‚‰ILSVRCï¼ˆImageNet Large Scale Visual Recognition Challengeï¼‰ã¨ã„ã†ç”»åƒèªè­˜AIã®ã‚³ãƒ³ãƒ†ã‚¹ãƒˆã‚’æ¯å¹´é–‹å‚¬ã—[^40-39]ã€ã“ã®é ƒãŠã‚ˆã³ã“ã‚Œä»¥å¾Œã®AIãƒ–ãƒ¼ãƒ ã®è§¦åª’ã¨ãªã£ãŸã¨ã„ãˆã‚‹ã€‚
2009å¹´ã®ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã®è«–æ–‡ã§ã€ä¸»ã«ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯å‡¦ç†ã®ãŸã‚ã«åˆ©ç”¨ã•ã‚Œã¦ã„ãŸãƒ—ãƒ­ã‚»ãƒƒã‚µã§ã‚ã‚‹**GPU**ï¼ˆGraphic Processor Unitï¼‰ã€2006å¹´ã«Nvidiaç¤¾ã«ã‚ˆã£ã¦é–‹ç™ºã•ã‚ŒãŸCUDA[^40-43]ã¨2008å¹´ã«ç™ºè¡¨ã•ã‚ŒãŸãã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«[^40-44]ã‚’åˆ©ç”¨ã—ã€AIã®å­¦ç¿’ã‚’ä¸¦åˆ—ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã§å‡¦ç†ã‚’é«˜é€ŸåŒ–ã—ãŸ[^40-36]ã€‚ã“ã‚Œä»¥æ¥ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å­¦ç¿’ãƒ»æ¨è«–ã«GPUãŒæ¡ç”¨ã•ã‚Œã‚‹ã“ã¨ãŒå¤šããªã£ãŸ[^40-37]ã€‚
ãã—ã¦ã€2012å¹´ã®ILSCRCã§AlexNetã¨å‘¼ã°ã‚Œã‚‹Deep CNNãƒ¢ãƒ‡ãƒ«ãŒç™ºè¡¨ã•ã‚Œ[^40-40]ã€ä»–ã‚’å‡Œé§•ã™ã‚‹æ€§èƒ½ã‚’è¦‹ã›ãŸã€‚AlexNetã¯5ã¤ã®ç•³ã¿è¾¼ã¿å±¤ã¨3ã¤ã®å…¨çµåˆå±¤ã¨ã„ã†æ·±ã„æ§‹é€ ã‚’ã—ã¦ãŠã‚Šå¤šãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ‰ã—ã¦ã„ãŸãŒã€CNNã§ã¯åˆã‚ã¦GPUã§å­¦ç¿’ã‚’è¡Œã†ã“ã¨ã§ã€ä»¥å‰ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚4å€é«˜é€Ÿã«å‡¦ç†ã§ããŸ[^40-38] [^40-41] [^40-42]ã€‚ã“ã®æˆæœã«ã‚ˆã‚Šã€Deep LearningãŒå¤¢ç‰©èªã§ã¯ãªã„ã“ã¨ã€å®Ÿç”¨åŒ–ã™ã‚‹æ–¹æ³•ã‚’ä¸–ç•Œã«ç¤ºã—ãŸã¨ã„ãˆã‚‹ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã®æ™®åŠãŒç¶šãã€2000å¹´åˆæœŸã‚ãŸã‚Šã‹ã‚‰Web2.0ã¨å‘¼ã°ã‚Œã‚‹æ™‚ä»£ã«å…¥ã‚‹[^40-45]ã€‚Facebookï¼ˆ2004å¹´[^40-46]ï¼‰ã€Youtubeï¼ˆ2005å¹´[^40-47]ï¼‰ã€Twitterï¼ˆ2006å¹´[^40-48]ï¼‰ã‚’ã¯ã˜ã‚ã¨ã—ãŸå‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æœ‰ã™ã‚‹Webã‚µãƒ¼ãƒ“ã‚¹ãŒç¶šã€…ã¨ç«‹ã¡ä¸ŠãŒã‚Šã€2006å¹´ã”ã‚ã‹ã‚‰ã®Wi-Fiã®æ™®åŠã‚‚ã‚ã£ã¦[^40-49]ã€Webä¸Šã§äººã€…ãŒæ´»å‹•ã™ã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚ã•ã‚‰ã«ã€MySQLã‚„PostgreSQLãªã©ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã®æˆé•·[^40-50]ã‚„2008å¹´ã”ã‚ã®IoTï¼ˆInternet of Thingsï¼‰ã®èª•ç”Ÿ[^40-51]ãªã©ã€ç™ºç”Ÿã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒå¢—åŠ ã™ã‚‹æ˜ã‚‰ã‹ãªå…†å€™ãŒè¦‹ãˆå§‹ã‚ã‚‹ã€‚ã“ã®ã‚ˆã†ãªæµã‚Œã‚‚ã‚ã‚Šã€2009å¹´ã®IDCï¼ˆInternational Data Corporationï¼‰ç¤¾ã®èª¿æŸ»ã§ã¯2020å¹´ã¾ã§ã«ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯44å€ã®35ã‚¼ã‚¿ãƒã‚¤ãƒˆã«å¢—åŠ ã™ã‚‹ï¼ˆData explosionï¼‰ã¨äºˆæ¸¬ã•ã‚Œå¤§ããªåéŸ¿ã‚’å‘¼ã‚“ã [^40-52]ã€‚ãã‚Œã«ã‚ˆã‚Šå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒé‡è¦ã¨ã•ã‚Œã¦ã„ã‚‹AIã€ç‰¹ã«æ©Ÿæ¢°å­¦ç¿’ã€ç‰¹ã«Deep Learningã«ã‚ˆã‚ŠæœŸå¾…ãŒã‹ã‹ã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚
ã¾ãŸã€2008å¹´ã«Gitã‚’ä½¿ç”¨ã—ãŸã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã®ãŸã‚ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã‚ã‚‹GithubãŒå…¬é–‹[^40-54]ã€ã“ã®ã“ã‚å‹¢ã„ã‚’ã¤ã‘ã¦ã„ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã‚ã‚‹Pythonã«ã¤ã„ã¦[^40-55]ã€æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãŒå®¹æ˜“ã«ãªã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚ã‚‹scikit-learnï¼ˆ2007å¹´[^40-57]ï¼‰ã€Theanoï¼ˆ2007å¹´[^40-56]ï¼‰ãªã©ãŒåˆ©ç”¨å¯èƒ½ã¨ãªã‚Šã€AIé–‹ç™ºã®æ•·å±…ã‚‚ã¾ã™ã¾ã™ä¸‹ãŒã£ãŸã„ãˆã‚‹ã€‚

more Moore, more than moore(2009, 2010)
http://www.itrs2.net/uploads/4/9/7/7/49775221/irc-itrs-mtm-v2_3.pdf
AWS released GPU instance(2010)
https://aws.amazon.com/jp/blogs/aws/new-gpu-equipped-ec2-p4-instances-for-machine-learning-hpc/

> ![Data growth and expansion (IDC, 2009)](/images/ai_history/IDC_2009.png)

[^40-1]:[A Quick History of Neural Networks](https://www.analyticsvidhya.com/blog/2020/09/quick-history-neural-networks/)
[^40-2]:[Explained: Neural networks](https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414)
[^40-3]:[*Hacker News*: Neural networks in the 1990s](https://news.ycombinator.com/item?id=36385809)
[^40-4]:[n-grams: AI Terms Explained](https://www.playerzero.ai/advanced/ai-terms-explained/n-grams-ai-terms-explained)
[^40-5]:[A Brief History of Large Language Models](https://www.linkedin.com/pulse/brief-history-large-language-models-bob/)
[^40-6]:[ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ãƒˆãƒ«ãƒã‚·ãƒ³ã¨ã‚«ãƒ¼ãƒãƒ«æ³•](https://orsj.org/wp-content/corsj/or65-6/or65_6_304.pdf)
[^40-7]: [Maximum Margin Separating Hyperplane in Scikit Learn](https://www.geeksforgeeks.org/maximum-margin-separating-hyperplane-in-scikit-learn/)
[^40-8]: [Top 4 advantages and disadvantages of Support Vector Machine or SVM](https://dhirajkumarblog.medium.com/top-4-advantages-and-disadvantages-of-support-vector-machine-or-svm-a3c06a2b107)
[^40-9]: [Kernel methoc in *Wikipedia*](https://en.wikipedia.org/wiki/Kernel_method)
[^40-10]:[ãƒ­ãƒœãƒƒãƒˆã«ã‚ˆã‚‹ã‚¨ãƒ³ã‚¿ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆå¸‚å ´ã‚’å‰µé€ ã™ã‚‹4è¶³æ­©è¡Œå‹ã‚¨ãƒ³ã‚¿ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆãƒ­ãƒœãƒƒãƒˆ "AIBOï¼ˆã‚¢ã‚¤ãƒœï¼‰"ã®è²©å£²é–‹å§‹](https://www.sony.com/ja/SonyInfo/News/Press/199905/99-046/)
[^40-11]:[Artificial Intelligence Robot](https://www.techopedia.com/definition/14242/artificial-intelligence-robot-aibo)
[^40-12]:[iRobot Introduces Roombaâ„¢ Intelligent FloorVac - The First Automatic Floor Cleaner In The U.S.](https://media.irobot.com/2002-09-18-iRobot-Introduces-Roomba-Intelligent-FloorVac-The-First-Automatic-Floor-Cleaner-In-The-U-S)
[^40-13]:[MNIST database in *Wikipedia*](https://en.wikipedia.org/wiki/MNIST_database#cite_note-8)
[^40-14]:[The History of Neural Networks](https://dataconomy.com/2017/04/19/history-neural-networks/)
[^40-15]:[Gradient-Based Learning Applied to Document Recognition](https://axon.cs.byu.edu/~martinez/classes/678/Papers/Convolution_nets.pdf)
[^40-16]:[ãƒã‚¤ã‚¯ãƒ­ãƒ—ãƒ­ã‚»ãƒƒã‚µã®èª•ç”Ÿã‹ã‚‰Windows 95ã®ç™»å ´ã¾ã§ã‚’æŒ¯ã‚Šè¿”ã‚‹](https://pc-kaden.medy.jp/p/a6da8c2a-03c6-444a-bb3d-f5c7af00ab94)
[^40-17]:[1995 Was The Most Important Year For The Web](https://thehistoryoftheweb.com/complete-history/1995-was-the-most-important-year-for-the-web/)
[^40-18]:[Deep learningâ€™s origins and pioneers](https://www.mckinsey.com/featured-insights/artificial-intelligence/deep-learnings-origins-and-pioneers)
[^40-19]:[LONG SHORT-TERM MEMORY](https://www.bioinf.jku.at/publications/older/2604.pdf)
[^40-20]:[What is Long Short Term Memory (LSTM) - Complete Guide](https://www.knowledgehut.com/blog/web-development/long-short-term-memory#long-short-term%C2%A0memory-networks)
[^40-21]: [Wang, Xin & Liu, Yuanchao & Sun, Chengjie & Wang, Baoxun & Wang, Xiaolong. (2015). Predicting Polarities of Tweets by Composing Word Embeddings with Long Short-Term Memory. 1343-1353. 10.3115/v1/P15-1130. ](https://www.researchgate.net/publication/301404520_Predicting_Polarities_of_Tweets_by_Composing_Word_Embeddings_with_Long_Short-Term_Memory)
[^40-22]:[25 years ago today: How Deep Blue vs. Kasparov changed AI forever](https://aibusiness.com/ml/25-years-ago-today-how-deep-blue-vs-kasparov-changed-ai-forever)
[^40-23]:[Gartner Acquisitions](https://www.gartner.com/en/about/acquisitions)
[^40-24]:[What makes Big Data, Big Data? Exploring the ontological characteristics of 26 datasets](https://journals.sagepub.com/doi/pdf/10.1177/2053951716631130)
[^40-25]:[Chapter 9 - The Big Data and Artificial Intelligence: Opportunities and Challenges to Modernise the Policy Cycle](https://www.sciencedirect.com/science/article/pii/B9780128225967000097)
[^40-26]:[Torch: a modular machine learning software library](https://infoscience.epfl.ch/record/82802?ln=en)
[^40-27]:[A Short History Of Deep Learning â€” Everyone Should Read](https://bernardmarr.com/a-short-history-of-deep-learning-everyone-should-read/)
[^40-28]:[Introduction To Deep Learning - Logix_Quest - Medium](https://aminazahid45.medium.com/introduction-to-deep-learning-334c0c01a145)
[^40-29]:[Auto-encoder based dimensionality reduction](https://www.sciencedirect.com/science/article/abs/pii/S0925231215017671)
[^40-30]:[Reducing the Dimensionality of Data with Neural Networks](https://www.cs.toronto.edu/~hinton/absps/science.pdf)
[^40-31]:[Hands-On Machine Learning with R: Chapter 19 Autoencoders](https://bradleyboehmke.github.io/HOML/autoencoders.html)
[^40-32]:[Auto-Encoders in Deep Learningâ€”A Review with New Perspectives](https://www.mdpi.com/2227-7390/11/8/1777)
[^40-33]:[Lecture 12 Handwritten Digit (MNIST) Recognition Using Deep Neural Networks](https://bkict-ocw.knu.ac.kr/caster/file/lecture/5DE9F88D7ADC6.pdf)
[^40-34]:[ImageNet: A Large-Scale Hierarchical Image Database](https://image-net.org/static_files/papers/imagenet_cvpr09.pdf)
[^40-35]:[ImageNet: A Pioneering Vision for Computers](https://www.historyofdatascience.com/imagenet-a-pioneering-vision-for-computers/)
[^40-36]:[Large-scale Deep Unsupervised Learning using Graphics Processors](http://robotics.stanford.edu/~ang/papers/icml09-LargeScaleUnsupervisedDeepLearningGPU.pdf)
[^40-37]:[A Brief History of GPUs](https://medium.com/neuralmagic/a-brief-history-of-gpus-27122d8fd45)
[^40-38]:[A practical experiment for comparing LeNet, AlexNet, VGG and ResNet models with their advantages and disadvantages.](https://tejasmohanayyar.medium.com/a-practical-experiment-for-comparing-lenet-alexnet-vgg-and-resnet-models-with-their-advantages-d932fb7c7d17)
[^40-39]:[ImageNet database in *Wikipedia*](https://en.wikipedia.org/wiki/ImageNet)
[^40-40]:[ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
[^40-41]:[AlexNet and ImageNet: The Birth of Deep Learning](https://www.pinecone.io/learn/series/image-search/imagenet/)
[^40-42]:[The data that transformed AI researchâ€”and possibly the world](https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world)
[^40-43]:[About CUDA](https://developer.nvidia.com/about-cuda)
[^40-44]:[Manycore Parallel Computing with CUDA](https://developer.download.nvidia.com/presentations/2008/ICS2008/ICS2008_Keynote_MarkHarris_public.pdf)
[^40-45]:[The Evolution of the Internet: Web 1.0, Web 2.0 and Web 3.0.](https://www.linkedin.com/pulse/evolution-internet-web-10-20-30-deepak-lyngdoh/)
[^40-46]:[History of Facebook in *Wikipedia*](https://en.wikipedia.org/wiki/History_of_Facebook)
[^40-47]:[History of Youtube in *Wikipedia*](https://en.wikipedia.org/wiki/History_of_YouTube)
[^40-48]:[Twitter in *Wikipedia*](https://en.wikipedia.org/wiki/Twitter)
[^40-49]:[15 years of WiFi](https://fon.com/fon-wifi-infographic/)
[^40-50]:[Database Management System - DBMS](https://padakuu.com/history-of-database-systems-306-article)
[^40-51]:[A Brief History of Internet of Things (IoT)](https://bytebeam.io/blog/a-brief-history-of-internet-of-things/)
[^40-52]:[IDC: Data explosion goes into the Zettabytes](https://www.itpro.com/622942/idc-data-explosion-goes-into-the-zettabytes)
[^40-53]:[The main challenges and issues of big data management](https://www.researchgate.net/publication/272696610_The_main_challenges_and_issues_of_big_data_management)
[^40-54]:[GitHub in *Wikipedia*](https://en.wikipedia.org/wiki/GitHub)
[^40-55]:[The Rise of the Python Programming Language](https://www.udacity.com/blog/2021/01/the-rise-of-the-python-programming-language.html)
[^40-56]:[Theano in *Wikipedia*](https://en.wikipedia.org/wiki/Theano_(software))
[^40-57]:[scikit-learn in *Wikipedia*](https://en.wikipedia.org/wiki/Scikit-learn)
[^40-58]:[The graph neural network model](https://ro.uow.edu.au/cgi/viewcontent.cgi?article=10501&context=infopapers)
[^40-59]:[What Are Graph Neural Networks?](https://blogs.nvidia.com/blog/2022/10/24/what-are-graph-neural-networks/)

## 2013å¹´ã”ã‚ä»¥é™ ï¼šDeep Learning
2013å¹´é ƒã«ã€ãƒ¡ãƒ‡ã‚£ã‚¢å ±é“ã«ã€ŒBig Techã€ã¨ã„ã†æŠ€è¡“ç³»å¤§ä¼æ¥­ï¼ˆBig Fourã¯Googleã€Amazonã€Facebookã€Appleã€Big Fiveã¯ãã‚Œã‚‰ã«åŠ ãˆã¦Microsoftï¼‰ã‚’è¡¨ã™ç”¨èªãŒç¾ã‚Œã¯ã˜ã‚ãŸ[^50-1] [^50-2]ã€‚ã“ã‚Œã‚‰ã®ä¼æ¥­ã¯ä¾‹ãˆã°ã€AppleãŒéŸ³å£°èªè­˜ã®ãƒ‡ã‚¸ã‚¿ãƒ«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã‚ã‚‹Siriã‚’iPhone 4Sã«å®Ÿè£…ï¼ˆ2011å¹´ï¼‰[^50-3]ã€FacebookãŒFAIRï¼ˆFacebook Artificial Intelligence Researchï¼‰ã‚’è¨­ç«‹ï¼ˆ2013å¹´ï¼‰[^50-6]ã€GoogleãŒè‹±å›½ã®AIã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—DeepMindç¤¾ã‚’è²·åï¼ˆ2014å¹´ï¼‰[^50-5]ã€AmazonãŒã‚¹ãƒãƒ¼ãƒˆã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã«ãƒãƒ¼ãƒãƒ£ãƒ«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆAlexaã‚’æ­è¼‰ï¼ˆ2014å¹´ï¼‰[^50-4]ã€MicrosoftãŒãƒ‡ã‚¸ã‚¿ãƒ«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆCortanaã‚’ãƒªãƒªãƒ¼ã‚¹ï¼ˆ2014å¹´ï¼‰ãªã©[^50-7]ã€AIã«å¯¾ã—ã¦ã‚‚éå¸¸ã«ç©æ¥µçš„ãªå‹•ãã‚’è¦‹ã›ã¦ã„ãŸã€‚
ã“ã®é ƒã€CPUæ€§èƒ½ã®ä¸€ã¤ã§ã‚ã‚‹ã‚¯ãƒ­ãƒƒã‚¯å‘¨æ³¢æ•°ã¯é ­æ‰“ã¡çŠ¶æ…‹ã¨ãªã£ã¦ã„ãŸãŒã€ãƒãƒ«ãƒã‚³ã‚¢åŒ–ã€ä»®æƒ³åŒ–ç­‰ã«ã‚ˆã‚Šã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ã•ã‚‰ã«é«˜æ€§èƒ½ã«ãªã£ã¦ã„ã£ãŸ[^50-13]ã€‚ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢çš„ã«ã‚‚ã•ã‚‰ã«è¤‡é›‘ãªå‡¦ç†ãŒå¯èƒ½ã¨ãªã£ã¦ã„ãä¸­ã€Deep Learningã‚‚ã‚ˆã‚Šé«˜åº¦åŒ–ã—ã¦ã„ãã€‚
2013å¹´ã«ã€å…¥åŠ›ã‚’ç¤ºã™ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã‚’ç”Ÿæˆã™ã‚‹**Embedding**ã¨å‘¼ã°ã‚Œã‚‹å‡¦ç†ã«ã‚ˆã‚Šã€å˜èªã®æ„å‘³ã‚’è¡¨ç¾ã—ãŸWord Embeddingã‚’ç”Ÿæˆã™ã‚‹Word2vecã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ãŒGoogleã®æŠ€è¡“è€…ã«ã‚ˆã‚Šç™ºè¡¨ã•ã‚ŒãŸ[^50-11] [^50-12]ã€‚ãã—ã¦2014å¹´ã«ç™ºè¡¨ã•ã‚ŒãŸSeq2seqï¼ˆSequence-to-Sequenceï¼‰ãƒ¢ãƒ‡ãƒ«ã§ã¯[^50-18]ã€RNNã§Word Embeddingã‚’è¡Œã„ã€ã•ã‚‰ã«RNNã§åˆ¥ã®è¨€èªã«å¤‰æ›ã™ã‚‹ã¨ã„ã†æ©Ÿæ¢°ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ãŒææ¡ˆã•ã‚ŒãŸã€‚ã“ã®ã‚ˆã†ãªEmbeddingã‚’è¡Œã†Encoderã¨ã€ãã‚Œã‚’ã‚‚ã¨ã«å‡ºåŠ›ã‚’è¡Œã†Decoderã‹ã‚‰ãªã‚‹æ§‹é€ ã‚’ã€[**Encoder-Decoder**](https://lethediana.sakura.ne.jp/tech/archives/summary-ja/2173/)ã¨å‘¼ã³[^50-19]ã€è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆç¿»è¨³ï¼‰ã§ã„ã†ã¨è¤‡é›‘ãªæ–‡æ§‹é€ ã‚„æ…£ç”¨çš„ãªè¡¨ç¾ãªã©ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ãŸå‡¦ç†ã‚’å¯èƒ½ã¨ã—ãŸ[^50-20]ï¼ˆæ§‹é€ ãƒ»æ©Ÿèƒ½ã®å®šæ€§çš„ãªã¾ã¨ã‚ã¯[ã“ã¡ã‚‰](https://lethediana.sakura.ne.jp/tech/archives/summary-ja/2173/)ã‚‚ã©ã†ãï¼‰ã€‚
2014å¹´ã«Stanfordå¤§ã«ã‚ˆã‚ŠGloVeã¨å‘¼ã°ã‚Œã‚‹äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒç™ºè¡¨ã•ã‚Œ[^50-16]ã€ç‰¹ã«æ©Ÿæ¢°ç¿»è¨³ã§ã¯Word EmbeddingãŒä¸»æµã«ãªã£ã¦ã„ã£ãŸ[^50-14]ã€‚

> **note**
Word embeddingã¨ã„ã†è¨€è‘‰ã¯ã€2003å¹´ã«æå”±ã•ã‚Œã€2008å¹´ã®*A unified architecture for natural language processing*ã¨ã„ã†è«–æ–‡ã§åˆã‚ã¦å®Ÿè¨¼ã•ã‚ŒãŸã¨ã•ã‚Œã‚‹[^50-14]ã€‚å…¥åŠ›ã‚’ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã«ç„¼ãç›´ã›ã°ã‚ˆã„ã®ã§ã€CNNã®ç•³ã¿è¾¼ã¿å±¤ã‚’ã€Image Embeddingã¨ã™ã‚‹å ´åˆã‚‚ã‚ã‚‹[^50-15]ã€‚

ãã—ã¦ã“ã®2014å¹´ã«ã¯ã€2ç¨®é¡ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆï¼ˆãã‚Œãã‚Œã€Generatorã€Descriminatorã¨å‘¼ã°ã‚Œã‚‹ã€‚è©³ç´°ã¯å‰²æ„›ï¼‰ã‚’ç”¨ã„ã¦AIãŒç”»åƒã‚’ç”Ÿæˆã§ãã‚‹äº‹ä¾‹ã‚’ã—ã‚ã—ãŸ**GAN**ï¼ˆGenerative Adversarial Neural networkï¼‰ã¨ã„ã†ãƒ¢ãƒ‡ãƒ«ãŒç™ºè¡¨ã•ã‚Œ[^50-22]ã€ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãªèƒ½åŠ›ã‚’æŒã¤AIã€ã™ãªã‚ã¡**ç”ŸæˆAI**ï¼ˆ**Generative AI**ï¼‰ãŒè¦‹ãˆã¦ããŸã€‚

ã“ã®é ƒã€ãƒ‰ã‚¤ãƒ„ã®[Industrie 4.0](https://www.plattform-i40.de/IP/Navigation/EN/Home/home.html)ï¼ˆ2013å¹´ã«ç™ºè¡¨ã€2015å¹´ã«æ‹¡å¤§[^50-27]ï¼‰ä¸­å›½ã®[Made in China 2025ï¼ˆä¸­å›½è£½é€ 2025ï¼‰](https://english.www.gov.cn/2016special/madeinchina2025/)ï¼ˆ2015å¹´ï¼‰ã€æ—¥æœ¬ã®[Society 5.0](https://www8.cao.go.jp/cstp/society5_0/)ï¼ˆ2016å¹´ï¼‰ã€ã‚¢ãƒ¡ãƒªã‚«ã®[ç±³å›½AIç ”ç©¶é–‹ç™ºæˆ¦ç•¥è¨ˆç”»ï¼ˆNational Artificial Intelligence Research and Development Strategic Planï¼‰](https://www.nitrd.gov/PUBS/national_ai_rd_strategic_plan.pdf)ï¼ˆ2016å¹´ï¼‰ãªã©[^50-28]ã€ã®æˆ¦ç•¥ãªã©AIã‚’çµ„ã¿è¾¼ã‚“ã æ”¿ç­–ãƒ¬ãƒ™ãƒ«ã®å‹•ãã‚‚æ´»ç™ºåŒ–ã—ã€å›½å®¶ã¨ã—ã¦AIæŠ€è¡“ã‚’å‰æã¨ã—ãŸç¤¾ä¼šã‚’å¤§ã€…çš„ã«æ‰“ã¡ä¸Šã’ã‚‹ã‚ˆã†ã«ãªã£ã¦ããŸã€‚
ã¾ãŸã€AIç ”ç©¶ã«ãŠã„ã¦ã‚‚ã€2015å¹´ã«ã¯ã€Googleç¤¾ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ã‚ˆã‚ŠKeras[^50-8]ã€æ—¥æœ¬ã®Preferred Networksç¤¾ã«ã‚ˆã‚ŠChainer[^50-9]ã€Googleç¤¾ã«ã‚ˆã‚ŠTensorflowã€ç¿Œ2016å¹´ã«Facebookç¤¾ã‚ˆã‚ŠPyTorch[^50-10]ã¨ã„ã†ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®GPUã‚’ã‚µãƒãƒ¼ãƒˆã—ãŸPythonãƒ™ãƒ¼ã‚¹ã®æ©Ÿæ¢°å­¦ç¿’ãƒ»Deep Learningã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã€ã•ã‚‰ã«AIãƒ»æ©Ÿæ¢°å­¦ç¿’ã«å¯¾ã™ã‚‹å–ã‚Šçµ„ã¿ã®æ•·å±…ãŒå¤§å¹…ã«ä¸‹ãŒã‚‹ã€‚ã•ã‚‰ã«åŒ2015å¹´ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®åˆ©æ´»ç”¨ãƒ•ã‚§ãƒ¼ã‚ºã®è€ƒãˆæ–¹ã¨ã—ã¦ã€2009å¹´ã«ç™ºæ¡ˆã•ã‚ŒãŸDevOpsï¼ˆDevelopment Operationsï¼‰ã®åŸå‰‡[^50-26]ã‚’æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿è¾¼ã‚“ã ã‚·ã‚¹ãƒ†ãƒ ã«é©ç”¨ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã®è‡ªå‹•åŒ–ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’æ¨é€²ã§ãã‚‹MLOpsï¼ˆMachine Operationsï¼‰ã¨ã„ã†ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚‚æ³¨ç›®ã•ã‚Œå§‹ã‚ãŸ[^50-23] [^50-24] ã€‚
ä¸–é–“çš„ã«ã‚‚ã€Googleç¤¾ï¼ˆå³å¯†ã«ã¯DeepMindç¤¾ï¼‰ã®AlphaGoã¨ã„ã†AIãŒå›²ç¢ã®ä¸–ç•Œãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ã«å‹åˆ©ã—ã€å¤§ããªè©±é¡Œã‚’å‘¼ã‚“ã [^50-29]ã€‚

2015å¹´ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã•ã‚‰ãªã‚‹å¤šå±¤åŒ–ã«ä¼´ã†å‹¾é…æ¶ˆå¤±ãƒ»å‹¾é…çˆ†ç™ºå•é¡Œã¸ã®å¯¾ç­–ã¨ã—ã¦ã€Microsoft Researchç¤¾ã«ã‚ˆã‚ŠResNetï¼ˆResidual Networkï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å±¤ã‚’é£›ã°ã—ã¦ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’çµåˆã•ã›ã‚‹ï¼ˆã‚¹ã‚­ãƒƒãƒ—æ¥ç¶šï¼‰æ§‹é€ ã‚’æŒã£ãŸãƒ¢ãƒ‡ãƒ«ãŒææ¡ˆã•ã‚ŒãŸ [^50-30] [^50-31]ã€‚ ã“ã®æŠ€è¡“ã«ã‚ˆã‚Šã€æ•°ç™¾æ•°åƒã®å±¤ã‚’æŒã¤ã€ã¾ã™ã¾ã™æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¯èƒ½æ€§ãŒè¦‹å‡ºã•ã‚ŒãŸ[^50-32]ã€‚
ãã—ã¦ã€Seq2seqãƒ¢ãƒ‡ãƒ«ã§Encoderã®å‡ºåŠ›ãŒå›ºå®šé•·ã§ã‚ã‚‹ãŸã‚é•·ã„å…¥åŠ›ã«å¯¾å¿œã—ã¥ã‚‰ã„ã“ã¨ãªã©ã‚’å•é¡Œç‚¹ã¨ã—[^50-35]ã€**Attentionæ©Ÿæ§‹**ã¨å‘¼ã°ã‚Œã‚‹DecoderãŒæ³¨ç›®ã™ã¹ãéƒ¨åˆ†ã‚’ç¤ºã™ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å®Ÿè£…ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒææ¡ˆã•ã‚Œã€åˆ¶åº¦ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸï¼ˆ2015å¹´ã®è«–æ–‡[^50-37]ãŒå¤šãå¼•ç”¨ã•ã‚ŒãŸ[^50-34]ï¼‰[^50-33] [^50-36]ã€‚ã“ã®Attentionæ©Ÿæ§‹ã‚’å¿œç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚„[^50-39]ã€ç”»åƒå‡¦ç†AIã«é©ç”¨ã—ãŸä¾‹ãªã©[^50-40]ã€ãã®å¾Œã•ã¾ã–ã¾ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®Attentionæ©Ÿæ§‹ãŒææ¡ˆã•ã‚ŒãŸï¼ˆAttentionæ©Ÿæ§‹ã®è©³ç´°ã¯[ã“ã¡ã‚‰](https://lethediana.sakura.ne.jp/tech/archives/summary-ja/2170/)ã‚‚ã©ã†ãï¼‰ã€‚
ãŸã ã—ã€Attentionæ©Ÿæ§‹ãŒé«˜ç²¾åº¦åŒ–ã«å¤§ããè²¢çŒ®ã—ãŸä¸€æ–¹ã§ã€RNNã‚’ç”¨ã„ãŸEncoder-Decoderãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã†ãªã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ãªæ§‹é€ ã§ã¯å¤§è¦æ¨¡ãªå…¥åŠ›ã«å¯¾ã—ã¦ã€è¨ˆç®—ã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã‚‹ã¨ã„ã†æ¬ ç‚¹ãŒã‚ã£ãŸ[^50-43]ã€‚ã“ã‚Œã«å¯¾ã—ã¦ã€ãã“ã§2017å¹´ã«Multi-head Attentionã¨ã„ã†æ–¹å¼ã®Attentionæ©Ÿæ§‹ã‚’æ­è¼‰ã—ã¦ä¸¦åˆ—è¨ˆç®—å¯èƒ½ã¨ãªã£ãŸã€**Transformer**ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ãŒç™ºè¡¨ã•ã‚ŒãŸ[^50-38]ã€‚ã“ã®Transformerã¯å…¥åŠ›ã®å…¨ä½“ã‹ã‚‰æ³¨ç›®ã™ã¹ãéƒ¨åˆ†ã‚’è€ƒæ…®ã•ã›ã‚‹ç‚¹ã§ã€å…¥åŠ›ã®ã†ã¡ç‰¹å®šã®éƒ¨åˆ†ã®å‰å¾Œé–¢ä¿‚ã‚’åˆ†æã™ã‚‹RNNãªã©ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã¯ã€æ ¹æœ¬çš„ã«å‹•ä½œãŒç•°ãªã‚Š[^50-41] [^50-42]ã€CNNã‚„RNNã‚ˆã‚Šè¨ˆç®—é‡ãŒæŠ‘ãˆã‚‰ã‚Œã€è¨“ç·´ãŒå®¹æ˜“ã§ã€ä¸¦åˆ—å‡¦ç†ã‚‚ã—ã‚„ã™ã„ãªã©ã®ç‰¹é•·ã‚’æŒã¤[^50-44]ã€‚
ã¾ãŸã“ã®é ƒã€Industrie 4.0ã®ã‚­ãƒ¼ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã®ä¸€ã¤ã«AIãŒæŒ™ã’ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ã‚„[^50-45] [^50-46]ã€ã“ã®é ƒã®AIæŠ€è¡“ã¸ã®æŠ•è³‡å…ƒã®ãƒ¡ã‚¤ãƒ³ã¯æ”¿åºœã§ã¯ãªãç”£æ¥­ç•Œã¨ãªã£ãŸã“ã¨[^30-39]ï¼ˆDARPAãŒ2018å¹´ã«AI Next Campaignã‚’æ‰“ã¡å‡ºã™ãªã©ã€æ”¿åºœé–¢é€£ã‚‚æŠ•è³‡ã¯ç¶™ç¶šã—ã¦ã„ã‚‹[^50-48]ï¼‰ã€2006å¹´ã”ã‚ã‹ã‚‰æ™®åŠã—ã ã—ãŸã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æŠ€è¡“ã«ã‚ˆã‚Š[^50-47]ã€å¤šãã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãŒã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ã‹ã‚‰ã‚¯ãƒ©ã‚¦ãƒ‰ã¸ã¨ç§»è¡Œã—ã¦ã„ã£ãŸåå‹•ã‚„ã€ç¶šã€…ã¨AIã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒäººé–“ã®èƒ½åŠ›ã‚’è¶…ãˆã¦ãã¦ã„ã‚‹ã“ã¨ã‚‚ã‚ã‚Š[^50-57]ã€å°è¦æ¨¡ãƒªã‚½ãƒ¼ã‚¹ã§å‹•ä½œã™ã‚‹**Edge AI**ãŒæ³¨ç›®ã•ã‚Œã¦ããŸã€‚ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã¸ã®AIå®Ÿè£…ã«å‘ã‘ãŸé–‹ç™ºç’°å¢ƒã¨ã—ã¦ã‚‚ã€2017å¹´ã«TensorFlow LiteãŒç™ºè¡¨ã•ã‚Œ[^50-53]ã€2019å¹´ã«Pytorch MobileãŒç™ºè¡¨ã•ã‚ŒãŸ[^50-54]ã€‚

> ![State-of-the-art AI performance on benchmarks, relative to human performance](/images/ai_history/1691138939574.jpeg)

Transformerãƒ¢ãƒ‡ãƒ«ã¯éå¸¸ã«æœ‰ç”¨ã§ã‚ã‚Šã€2018å¹´ã«ã¯ç›®çš„ã‚„å­¦ç¿’æ–¹æ³•ãŒç•°ãªã‚‹Googleç¤¾ã®BERTï¼ˆBidirectional Encoder Representations from Transformersï¼‰ã‚„[^50-49] [^50-50]ï¼ˆ2019å¹´ã«ã¯Googleã®æ¤œç´¢ã«ã‚‚å°å…¥ã•ã‚Œã¦ã„ã‚‹[^50-56]ï¼‰ã€OpenAIç¤¾ã®GPTï¼ˆGenerative Pre-Trained Transformerï¼‰ã¨ã„ã£ãŸ[^50-51] [^50-52]ã€è‡ªç„¶è¨€èªç³»ã®AIãƒ¢ãƒ‡ãƒ«ãŒç™ºè¡¨ã•ã‚ŒãŸã€‚è¨€èªç³»ã®ãƒ¢ãƒ‡ãƒ«ã¯å¤§è¦æ¨¡ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã‚‹ã¨ä¸é€£ç¶šã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ã¦ãã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ã“ã¨ã€‚10å„„ï¼ˆBillionï¼‰å˜ä½ã§ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã‚‹ï¼‰ã‚’å¢—åŠ ã—ã¦ã„ã‚‹[^50-59]ã€‚

> ![Language Model Sizes Over times](https://twosigmaventures.com/wp-content/uploads/sites/2/Model-Size-Over-Time@4x.png)

ã“ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã¯ç‰¹ã«**LLMs**ï¼ˆLarge Language Models, å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã¨å‘¼ã°ã‚Œã€OpenAIç¤¾ã®GPT-3ï¼ˆ2020å¹´7æœˆï¼‰[^50-62]ã€GPT-3.5ï¼ˆ2022å¹´3æœˆï¼‰[^50-63]ã€GPT-4ï¼ˆ2023å¹´3æœˆï¼‰[^50-64]ã€Googleç¤¾ã®LaMDAï¼ˆ2021å¹´3æœˆï¼‰[^50-65]ã€PaLMï¼ˆ2022å¹´4æœˆï¼‰[^50-66]ã€PaLM-2ï¼ˆ2023å¹´3æœˆï¼‰[^50-67]ã€Geminiï¼ˆ2023å¹´12æœˆï¼‰[^50-68]ã€Metaç¤¾ã®LLaMaï¼ˆ2023å¹´2æœˆï¼‰[^50-60]ã€LLaMa-2ï¼ˆ2023å¹´7æœˆã€å„ªå…ˆãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã¨ã—ã¦Microsoftç¤¾ãŒæŒ™ã’ã‚‰ã‚ŒãŸï¼‰[^50-61]ã€Anthropicç¤¾ã®Claudeï¼ˆ2023å¹´3æœˆï¼‰[^50-69]ã€Claude2ï¼ˆ2023å¹´7æœˆï¼‰[^50-70]ãªã©ã€ç¾åœ¨ã§ã‚‚æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ãŒé–‹ç™ºã•ã‚Œã¦ã„ã‚‹ã€‚
ãã—ã¦LLMsã¯ã€è¿½åŠ ã®å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦Fine tuningã‚’è¡Œã†ã“ã¨ã§ç”¨é€”ã«ç‰¹åŒ–ã—ãŸã‚µãƒ¼ãƒ“ã‚¹ã«ã™ã‚‹ã“ã¨ãŒã§ã[^50-71]ã€ãã®æ„å‘³ã§**åŸºç›¤ãƒ¢ãƒ‡ãƒ«**ï¼ˆ**Foundation Model**ï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚‹[^50-72]ã€‚ä¸­ã§ã‚‚ã€GPT-3.5ã‚’Chatbotç”¨ã«Fine tuningã—ãŸ**ChatGPT**ã¨ã„ã†ã‚µãƒ¼ãƒ“ã‚¹ã¯ã€2022å¹´11æœˆã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¦2ã‹æœˆã§æœˆé–“1å„„äººã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ°é”ã—ãŸã¨æ¨å®šã•ã‚Œã€å²ä¸Šæœ€ã‚‚æ€¥é€Ÿã«æˆé•·ã—ã¦ã„ã‚‹æ¶ˆè²»è€…å‘ã‘ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨å‘¼ã°ã‚Œã¦ã„ã‚‹[^50-73]ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã€Œç”ŸæˆAIã€ã¨ã„ã†è¨€è‘‰ãŒçˆ†ç™ºçš„ã«æ™®åŠã—ã€ã‚ªãƒ•ã‚£ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã§ã‚ã‚‹[^50-74]Microsoft 365ã«ChatGPTã‚’çµ±åˆã—ãŸãŸã‚ã€æŠ€è¡“è€…ã§ãªãã¦ã‚‚AIã«è§¦ã‚Œã‚‹æ©Ÿæ¢°ãŒæ¿€å¢—ã—ãŸã€‚
ã“ã‚Œã«ä¼´ã„ã€å…ƒãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã™ã‚‹æƒ…å ±æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚’è¿½åŠ ã—ã¦ChatGPTã®ã‚ˆã†ãªLLMsã‚µãƒ¼ãƒ“ã‚¹ã®æ©Ÿèƒ½ã‚’æ‹¡å¼µã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚ã‚‹RAGï¼ˆRetrieval Augmentation Generationï¼‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„[^50-77]ã€ç”ŸæˆAIã«ç›®çš„ã®å‡ºåŠ›ã‚’ç”Ÿæˆã•ã›ã‚‹æŠ€è¡“ã¨ã—ã¦Prompt Engineeringãªã©[^50-78]ã€æ–°ã—ã„ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚‚ç¶šã€…å‡ºç¾ã—ã¦ã„ã‚‹ã€‚
Transformerã¯ãã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®é«˜ã•ã‹ã‚‰ä»–ã®åˆ†é‡ã«ã‚‚ç”¨ã¯æ‹¡å¤§ã—[^50-55] [^50-76]ã€ãƒã‚·ãƒ³ãƒ“ã‚¸ãƒ§ãƒ³ï¼ˆç”»åƒèªè­˜ï¼‰å‘ã‘ã®**Vision Transformer**ï¼ˆ2020å¹´ï¼‰ãªã©[^50-58]ã€å¾“æ¥ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒæ‹…ã£ã¦ããŸã‚¿ã‚¹ã‚¯ã‚’ä»£æ›¿ã™ã‚‹æ‰‹æ³•ã¨ã—ã¦ã‚‚ç”¨ã„ã‚‰ã‚Œå§‹ã‚ã¦ã„ã‚‹ã€‚ãã—ã¦ã€ç”ŸæˆAIã¨ã„ã†è¦³ç‚¹ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆã™ã‚‹text-to-imageãƒ¢ãƒ‡ãƒ«ã¨å‘¼ã°ã‚Œã‚‹åˆ†é‡ã‚‚ç™ºå±•ã—ã€Stability AIç¤¾ã®[Stable Diffusion](https://huggingface.co/spaces/stabilityai/stable-diffusion)ï¼ˆ2022å¹´ï¼‰ã€Midjourneyç¤¾ã®[Midjourney](https://www.midjourney.com/home/)ï¼ˆ2022å¹´ï¼‰ã€OpenAIç¤¾ã®[DALL-E3](https://openai.com/dall-e-3)ï¼ˆ2023å¹´ï¼‰ãªã©ãŒç™ºè¡¨ã•ã‚Œã¦ã„ã‚‹ã€‚

[^50-1]:[Big Tech in *Wikipedia*](https://en.wikipedia.org/wiki/Big_Tech)
[^50-2]:[Big Tech](https://academic-accelerator.com/encyclopedia/big-tech)
[^50-3]:[Apple's Siri and the Future of Artificial Intelligence](https://forbes.com/sites/erikkain/2011/10/15/apples-siri-and-the-future-of-artificial-intelligence/?sh=37bdf86d29a0)
[^50-4]:[Amazon Alexa in *Wikipedia*](https://en.wikipedia.org/wiki/Amazon_Alexa)
[^50-5]:[Google buys UK artificial intelligence startup Deepmind for Â£400m](https://www.theguardian.com/technology/2014/jan/27/google-acquires-uk-artificial-intelligence-startup-deepmind)
[^50-6]:[Meta AI in *Wikipedia*](https://en.wikipedia.org/wiki/Meta_AI)
[^50-7]:[A brief history of Cortana, Microsoft's trusty digital assistant](https://www.windowscentral.com/history-cortana-microsofts-digital-assistant)
[^50-8]:[The History of Keras: From Research Project to Industry Standard](https://ts2.space/en/the-history-of-keras-from-research-project-to-industry-standard/)
[^50-9]:[Chainer in *Wikipedia*](https://en.wikipedia.org/wiki/Chainer)
[^50-10]:[PyTorch: all about Facebookâ€™s Deep Learning framework](https://datascientest.com/en/pytorch-all-about-this-framework#:~:text=Based%20on%20the%20former%20Torch,a%20simple%20and%20efficient%20way.)
[^50-11]:[Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)
[^50-12]:[Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)
[^50-13]:[MULTI-CORE PROCESSORS](https://medium.com/nerd-for-tech/multi-core-processors-53ee2899f90f)
[^50-14]:[An overview of word embeddings and their connection to distributional semantic models](https://aylien.com/blog/overview-word-embeddings-history-word2vec-cbow-glove)
[^50-15]:[Image Embeddings explained](https://www.picsellia.com/post/image-embeddings-explained)
[^50-16]:[GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)
[^50-17]:[Sequence To Sequence ( Seq2Seq )](https://blog.octopt.com/sequence-to-sequence/)
[^50-18]:[Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
[^50-19]:[Sequence to Sequence (seq2seq) and Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)
[^50-20]:[The Benefits of AI Seq2Seq Models in Machine Translation and Language Processing](https://ts2.space/en/the-impact-of-ai-seq2seq-models-on-machine-translation-and-language-processing/)
[^50-21]:[AI-generated world: How Generative Adversarial Networks(GANs) are transforming whole industries today](https://www.linkedin.com/pulse/ai-generated-world-how-generative-adversarial-whole-industries-kusyy/)
[^50-22]:[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)
[^50-23]:[Hidden Technical Debt in Machine Learning Systems](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)
[^50-24]:[Secure MLOps solutions with Azure network security](https://learn.microsoft.com/en-us/azure/architecture/ai-ml/guide/network-security-mlops)
[^50-25]:[MLOps: æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹ç¶™ç¶šçš„ãƒ‡ãƒªãƒãƒªãƒ¼ã¨è‡ªå‹•åŒ–ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning?hl=ja)
[^50-26]:[What Is DevOps?](https://newrelic.com/devops/what-is-devops)
[^50-27]:[The background to Plattform Industrie 4.0](https://www.plattform-i40.de/IP/Navigation/EN/ThePlatform/Background/background.html)
[^50-28]:[Creation of the National Artificial Intelligence Research and Development Strategic Plan](https://onlinelibrary.wiley.com/doi/10.1609/aimag.v39i2.2803)
[^50-29]:[Artificial intelligence: Google's AlphaGo beats Go master Lee Se-dol](https://www.bbc.com/news/technology-35785875)
[^50-30]:[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)
[^50-31]:[Residual Networks (ResNet) â€“ Deep Learning](https://www.geeksforgeeks.org/residual-networks-resnet-deep-learning/)
[^50-32]:[The Impact of Residual Networks on the Advancement of AI](https://ts2.space/en/the-impact-of-residual-networks-on-the-advancement-of-ai/)
[^50-33]:[Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
[^50-34]:[Review â€” Neural Machine Translation by Jointly Learning to Align and Translate](https://sh-tsang.medium.com/review-neural-machine-translation-by-jointly-learning-to-align-and-translate-3b381fc032e3)
[^50-35]:[Seq2Seq with Attention](https://hackmd.io/@kkume/rkjOYwfKD)
[^50-36]:[Sequence to Sequence (seq2seq) and Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)
[^50-37]:[NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE](https://arxiv.org/pdf/1409.0473.pdf)
[^50-38]:[Attention Is All You Need](https://arxiv.org/abs/1706.03762)
[^50-39]:[Attention? Attention!](https://lilianweng.github.io/posts/2018-06-24-attention/)
[^50-40]:[Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://proceedings.mlr.press/v37/xuc15.pdf)
[^50-41]:[Transformers Can Mock Part of Human Brain](https://www.infoq.com/news/2022/10/transformers-mock-brain/)
[^50-42]:[AI models are powerful, but are they biologically plausible?](https://news.mit.edu/2023/ai-models-astrocytes-role-brain-0815)
[^50-43]:[Attention is all you need: Discovering the Transformer paper](https://towardsdatascience.com/attention-is-all-you-need-discovering-the-transformer-paper-73e5ff5e0634)
[^50-44]:[CRDS å›½ç«‹ç ”ç©¶é–‹ç™ºæ³•äººç§‘å­¦æŠ€è¡“æŒ¯èˆˆæ©Ÿæ§‹ ç ”ç©¶é–‹ç™ºæˆ¦ç•¥ã‚»ãƒ³ã‚¿ãƒ¼ ç ”ç©¶é–‹ç™ºã®ä¿¯ç°å ±å‘Šæ›¸ ã‚·ã‚¹ãƒ†ãƒ ãƒ»æƒ…å ±ç§‘å­¦æŠ€è¡“åˆ†é‡ï¼ˆ2023å¹´ï¼‰](https://www.jst.go.jp/crds/pdf/2022/FR/CRDS-FY2022-FR-04/CRDS-FY2022-FR-04_20102.pdf)
[^50-45]:[VDMA Digitalization & Industrie 4.0](https://www.vdma.org/digitalization-industry-40)
[^50-46]:[VDMA Artificial Intelligence](https://www.vdma.org/artificial-intelligence)
[^50-47]:[Dockerä¸€å¼·ã®çµ‚ç„‰ã«ã‚ãŸã‚Šã€æŠ¼ã•ãˆã‚‹ã¹ãContaineräº‹æƒ…](https://zenn.dev/ttnt_1013/articles/f36e251a0cd24e)
[^50-48]:[AI Next Campaign (Archived)](https://www.darpa.mil/work-with-us/ai-next-campaign)
[^50-49]:[Unleashing the Power of BERT: How the Transformer Model Revolutionized NLP](https://arize.com/blog-course/unleashing-bert-transformer-model-nlp/)
[^50-50]:[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
[^50-51]:[GPT: Generative Pre-Trained Transformer (2018)](https://kikaben.com/gpt-generative-pre-training-transformer-2018/)
[^50-52]:[Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
[^50-53]:[Announcing TensorFlow Lite](https://developers.googleblog.com/2017/11/announcing-tensorflow-lite.html)
[^50-54]:[Facebook launches PyTorch Mobile for edge ML on Android and iOS devices](https://venturebeat.com/ai/facebook-launches-pytorch-mobile-for-edge-ml-on-android-and-ios-devices/)
[^50-55]:[Stanford CS25: V2 I Introduction to Transformers w/ Andrej Karpathy](https://www.youtube.com/watch?v=XfpMkf4rD6E/)
[^50-56]:[ã€å›³è§£ã€‘BERTã¨ã¯ï¼ŸGoogleã®æ–°è‡ªç„¶è¨€èªå‡¦ç†ãŒã©ã†å½±éŸ¿ã™ã‚‹ã®ã‹](https://satori.marketing/marketing-blog/what-is-bert/)
[^50-57]:[4 Charts That Show Why AI Progress Is Unlikely to Slow Down](https://time.com/6300942/ai-progress-charts/)
[^50-58]:[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://openreview.net/forum?id=YicbFdNTTy)
[^50-59]:[The Promise and Perils of Large Language Models](https://twosigmaventures.com/blog/article/the-promise-and-perils-of-large-language-models/?ref=assemblyai.com)
[^50-60]:[Introducing LLaMA: A foundational, 65-billion-parameter large language model](https://ai.meta.com/blog/large-language-model-llama-meta-ai/)
[^50-61]:[Metaã¨ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã€ æ¬¡ä¸–ä»£Llamaã‚’ç™ºè¡¨](https://about.fb.com/ja/news/2023/07/meta-and-microsoft-introduce-the-next-generation-of-llama/)
[^50-62]:[OpenAIâ€™s new language generator GPT-3 is shockingly goodâ€”and completely mindless](https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/)
[^50-63]:[OpenAI GPT-3.5](https://lablab.ai/tech/openai/gpt3-5)
[^50-64]:[OpenAI GPT-4](https://lablab.ai/tech/openai/gpt4)
[^50-65]:[LaMDA: our breakthrough conversation technology](https://blog.google/technology/ai/lamda/)
[^50-66]:[Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance](https://blog.research.google/2022/04/pathways-language-model-palm-scaling-to.html)
[^50-67]:[Introducing PaLM 2](https://blog.google/technology/ai/google-palm-2-ai-large-language-model/)
[^50-68]:[Introducing Gemini: our largest and most capable AI model](https://blog.google/technology/ai/google-gemini-ai/)
[^50-69]:[Introducing Claude](https://www.anthropic.com/index/introducing-claude)
[^50-70]:[Claude 2](https://www.anthropic.com/index/claude-2)
[^50-71]:[The Ultimate Guide to LLM Fine Tuning: Best Practices & Tools](https://www.lakera.ai/blog/llm-fine-tuning-guide)
[^50-72]:[Foundation Models and LLMs: a Complete Guide](https://kili-technology.com/large-language-models-llms)
[^50-73]:[ChatGPT sets record for fastest-growing user base - analyst note](https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/)
[^50-74]:[The biggest blocker to LibreOffice adoption? LibreOffice.](https://www.dedoimedo.com/computers/libreoffice-adoption.html)
[^50-75]:[ChatGPTã‚’çµ±åˆã—ãŸOfficeã®æ–°æ©Ÿèƒ½ãŒã™ã”ã™ãã‚‹](https://www.gizmodo.jp/2023/05/microsoft-365-copilot-new-feature.html)
[^50-76]:[A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks](https://arxiv.org/abs/2306.07303)
[^50-77]:[Retrieval Augmented Generation (RAG) in Azure AI Search](https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview)
[^50-78]:[What is Prompt Engineering?](https://aws.amazon.com/what-is/prompt-engineering/)

# æœ€çµ‚ç¢ºèª

https://www.arxiv-vanity.com/papers/2109.01517/

https://www.lamsade.dauphine.fr/~cazenave/papers/games.pdf


Probabilistic AI
https://hawai.tech/ia-waves-and-evolution-of-hardware/


https://softjourn.com/insights/heuristic-programming#
Game Theory: In the 1950s and 1960s, researchers like Claude Shannon and Arthur Samuel developed early heuristics to explore optimal game strategies like chess and checkers. Their work paved the way for more advanced heuristic techniques used in game theory today.
Optimization: In the 1970s, researchers began developing metaheuristic optimization algorithms, such as genetic and simulated annealing, to find near-optimal solutions to complex optimization problems.
Machine Learning: The 1980s and 1990s witnessed significant advancements in machine learning techniques, such as decision trees and neural networks, which rely on heuristic methods to learn from data and make predictions.
Human-Computer Interaction: Heuristic evaluation, a method for identifying usability issues in user interfaces, was introduced by Jakob Nielsen in the 1990s, highlighting the application of heuristics in human-computer interaction.
As computer science continues to evolve, so do heuristic techniques, with researchers constantly developing new and innovative ways to apply heuristics to tackle increasingly complex problems.

Several focal areas in the quest for AI emerged between the 1950s and the 1970s.[148] Newell and Simon pioneered the foray into heuristic search, an efficient procedure for finding solutions in large, combinatorial spaces. In particular, they applied this idea to construct proofs of mathematical theorems, first through their Logic Theorist program, and then through the General Problem Solver.[149] In the area of computer vision, early work in character recognition by Selfridge and colleagues[150] laid the basis for more complex applications such as face recognition.[151] By the late sixties, work had also begun on natural language processing.[152] â€œShakeyâ€, a wheeled robot built at SRI International, launched the field of mobile robotics. Samuel's Checkers-playing program, which improved itself through self-play, was one of the first working instances of a machine learning system.[153] Rosenblatt's Perceptron,[154] a computational model based on biological neurons, became the basis for the field of artificial neural networks. Feigenbaum and others advocated [155]the case for building expert systemsâ€”knowledge repositories tailored for specialized domains such as chemistry and medical diagnosis.[156]
https://ai100.stanford.edu/2016-report/appendix-i-short-history-ai

But the real change I think in the field happened when it became feasible to store and capture large amounts of data. Back in those first days with the probabilistic systems, we didnâ€™t have much data. 
*Learning from Artificial Intelligenceâ€™s Previous Awakenings: The History of Expert Systems*

https://sites.bu.edu/cmcs/2017/11/16/growing-up-with-alexa-siri-and-other-a-i-technology/

https://www.washingtonpost.com/news/the-switch/wp/2017/06/05/why-apple-is-struggling-to-become-an-artificial-intelligence-powerhouse/

## åˆæœŸã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html

## æ•™å¸«ã‚¢ãƒªå­¦ç¿’ãƒ»æ•™å¸«ãªã—å­¦ç¿’ã®æµã‚Œ
Nearest neighbour approach
1967 â€“ Machines gained the ability to recognize patterns 
    The â€œnearest neighborâ€ algorithm was created,
https://www.isahit.com/blog/what-is-similarity-based-learning-in-supervised-machine-training
While traditional supervised learning focuses on predicting labels based on input data and unsupervised learning aims to find hidden structures within data, Similarity learning is somewhat in between.
https://www.datacamp.com/blog/what-is-similarity-learning
Similarity Based Learningã‹ã‚‰
1981, Gerald Dejong discovered Explanation Based Learning

Semi-supervised learning
Self-supervised learning


[Embeddings in Machine Learning: Everything You Need to Know](https://www.featureform.com/post/the-definitive-guide-to-embeddings)

> ![Embeddings can produce remarkable analogies.](https://developers.google.com/static/machine-learning/crash-course/images/linear-relationships.svg?hl=ja)
*Embeddings can produce remarkable analogies.*

[Facebookâ€™s artificial intelligence research team, FAIR, turns five. But what are its biggest accomplishments?](https://hub.packtpub.com/facebooks-artificial-intelligence-research-team-fair-turns-five-but-what-are-its-biggest-accomplishments/)

MNIST
Hopfiled networkã®è¨ˆç®—åŠ¹ç‡ã®æ‚ªã•
æ¬¡å…ƒã®å‘ªã„

## å¼·åŒ–å­¦ç¿’ã®æ­´å²
- Mean field?
- Monte calro
- Q-learning

## optimization
Optimizer selection
Tis section discusses the CNN learning process. Two major issues are included in the
learning process: the frst issue is the learning algorithm selection (optimizer), while the
second issue is the use of many enhancements (such as AdaDelta, Adagrad, and momentum) along with the learning algorithm to enhance the output.
https://ts2.space/en/the-evolution-of-ai-gradient-descent-a-historical-perspective-on-optimization-techniques/
https://arxiv.org/pdf/2212.09413.pdf

https://medium.com/@adi.fu7/ai-accelerators-part-ii-transistors-and-pizza-or-why-do-we-need-accelerators-75738642fdaa

# ä»Šå¾Œã®AIæŠ€è¡“
ç¤¾ä¼šå®Ÿè£…ã«å‘ã‘ãŸèª²é¡ŒãŒå¢—ãˆã¦ã„ã‚‹
## å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«
- ãƒ‡ãƒ¼ã‚¿é‡å¢—å¤§
- æ®‹ã‚Šã®5æ„Ÿï¼ˆè§¦è¦šã€å—…è¦šã€å‘³è¦š
- ãƒ¡ã‚¿ãƒãƒ¼ã‚¹ä¸Šã®ãƒ‡ãƒ¼ã‚¿
## ãƒãƒ¼ãƒ‰ã®é€²åŒ–
- ã‚¯ãƒ­ãƒƒã‚¯ã®é£½å’Œ
- AIãƒãƒ¼ãƒ‰ï¼ˆãƒãƒƒãƒ—ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‰ã®å‡ºç¾ï¼šã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£
- é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿
## AIå€«ç†
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åè¦‹ï¼ˆä»Šã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§AIãŒå­¦ç¿’ã™ã‚‹ã¨åŒ»è€…ã¯ç”·ã€çœ‹è­·å¸«ã¯å¥³ã¨ã„ã†åè¦‹ãŒå…¥ã£ã¦ã—ã¾ã†ç­‰ï¼‰
https://hypebeast.com/jp/2023/5/geoffrey-hinton-godfather-of-ai-quit-google
    - ç¤¾ä¼šçš„ãªå½±éŸ¿ãŒå¤§ãããªã£ã¦ã„ã‚‹æ˜¨ä»Šã€æŠ€è¡“ï¼ˆAIã®å‡ºåŠ›ã™ã‚‹çµæœã®ç²¾åº¦ï¼‰ã ã‘ã‚’è¿½ã„æ±‚ã‚ã¦ãŠã‘ã°ã‚ˆã„ãƒ•ã‚§ãƒ¼ã‚ºã§ã¯ãªããªã£ã¦ãã¦ã„ã‚‹ã€‚
    2018: EU guidelines for AI
- XAI
## Full automation
- CPS
- AIä½œã‚‹AI
- AIåŒå£«ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³

# ãŠã‚ã‚Šã«
AIæŠ€è¡“ã®é€²å±•ã¯ã¨ã©ã¾ã‚‹ã¨ã“ã‚ã‚’çŸ¥ã‚‰ãªã„ã©ã“ã‚ã‹ã€ã©ã‚“ã©ã‚“ã¨åŠ é€Ÿã—ã¦ã„ã‚‹ã€‚
ãã®ãŸã‚ã€ç¾æ™‚ç‚¹ã®æœ€æ–°æŠ€è¡“ãŒä½•ã‹ã‚’æ‹¾ã†ã ã‘ã§ã¯ãªãã€ç™ºå±•ã®æ­´å²ã‚’é ­ã«å…¥ã‚ŒãŸã†ãˆã§å‹•å‘ã‚’ã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ—ã—ã¦ã„ãã“ã¨ã§ã‚ˆã‚Šé©åˆ‡ã«ã€‚
ã¾ãŸã€æŠ€è¡“çš„ã«AIã‚’è¦‹ã‚‹éš›ã«ã¯ã€æœ¬æ¥ã¯æ•°å­¦çš„ãªè¦–ç‚¹ã‹ã‚‰ã‚‚ç™ºæ˜ã®å¤‰é·ã‚’è¾¿ã‚‹ã®ãŒãƒ™ã‚¹ãƒˆã ãŒã€æœ¬è¨˜äº‹ã§è¨˜ã—ãŸã‚ˆã†ãªçŠ¶æ³ã‚„èƒŒæ™¯ã®å…¨ä½“æ„Ÿã‚’æŠŠæ¡ã‚’ã—ã¦ãŠã‘ã°è©³ç´°ã«å…¥ã‚Šã‚„ã™ã„ã®ã§ã¯ãªã„ã‹ã¨æ€ã†ã€‚

## ã‚‚ã†ã¡ã‚‡ã£ã¨èª¿ã¹ãŸã„
- AutoML
- Gameç†è«–ã¨ã®é–¢é€£æ€§
    - https://www.lamsade.dauphine.fr/~cazenave/papers/games.pdf
- DeepFake
- GAFAã¨å‘¼ã¶ã®ã¯æ—¥æœ¬ã ã‘ï¼Ÿ
    - https://www.xkula.com/gafa-or-faang-japan/https://www.xkula.com/gafa-or-faang-japan/
- Astrocyteã¨Transformerã®é–¢ä¿‚
- PINNã«ã¤ã„ã¦

## PS
èª¿æŸ»ã—ãã‚Œã¦ã„ãªã„éƒ¨åˆ†ã‚‚ã‚ã‚‹ã®ã§ã€å‰²æ„›ã—ãŸéƒ¨åˆ†ã‚’åŠ ãˆã¦é›»å­æ›¸ç±åŒ–ã«æŒ‘æˆ¦ã—ã¦ã¿ã¦ã‚‚ã‚ˆã„ã‹ã‚‚ï¼Ÿ


# å‚è€ƒ
https://en.wikipedia.org/wiki/History_of_artificial_intelligence
https://en.wikipedia.org/wiki/History_of_artificial_neural_networks
https://ourworldindata.org/brief-history-of-ai
https://www.javatpoint.com/history-of-artificial-intelligence
https://www.coe.int/en/web/artificial-intelligence/history-of-ai
https://www.g2.com/articles/history-of-artificial-intelligence
https://www.dataversity.net/brief-history-deep-learning/
https://www.holloway.com/g/making-things-think/sections/the-birth-of-artificial-intelligence-19521956
https://aiqom.ai/en/blogs/The-Evolution-of-Artificial-Intelligence
https://www.sparkfun.com/news/7896

[^20-1]: [äººå·¥çŸ¥èƒ½ç”¨è¨€èª Lispã®ä»Šã¨å°†æ¥](https://www.jstage.jst.go.jp/article/jjsai/24/5/24_681/_pdf)
